# ğŸ”§ ê¸°ìˆ ìŠ¤íƒ ì„ ì • ê·¼ê±° ë° ì•„í‚¤í…ì²˜ ê²°ì •

## ê¸°ìˆ ìŠ¤íƒ ì„ ì • ì² í•™

> **í•µì‹¬ ì›ì¹™**: ë¬¸ì œ í•´ê²° ì í•©ì„± > ìµœì‹  ê¸°ìˆ  > íŒ€ ì—­ëŸ‰ > ìƒíƒœê³„ ì„±ìˆ™ë„
> 
> **ì˜ì‚¬ê²°ì • ê¸°ì¤€**: ì„±ëŠ¥, í™•ì¥ì„±, ê°œë°œ ìƒì‚°ì„±, ìœ ì§€ë³´ìˆ˜ì„±, ë¹„ìš© íš¨ìœ¨ì„±

---

## ğŸ¯ ë¬¸ì œ ë¶„ì„ ë° ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­

### í•´ê²°í•´ì•¼ í•  í•µì‹¬ ë¬¸ì œ
```yaml
1. ì‹¤ì‹œê°„ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬:
   í˜„ì¬: 1ê°œ ì–¸ë¡ ì‚¬ â†’ ëª©í‘œ: 18ê°œ ì–¸ë¡ ì‚¬ + ê³µì‹œ + SNS
   ì²˜ë¦¬ëŸ‰: 20 docs/s â†’ 100+ docs/s
   ì§€ì—°ì‹œê°„: ì‹¤ì‹œê°„ (<5ë¶„)

2. ë³µì¡í•œ ê´€ê³„ ë¶„ì„:
   ë…¸ë“œ: 10K â†’ 1M+ (Company, Person, News, Risk)
   ê´€ê³„: 50K â†’ 10M+ (ë‹¤ì–‘í•œ ì—°ê²° ê´€ê³„)
   ì¿¼ë¦¬: ë‹¨ìˆœ ì¡°íšŒ â†’ 6ë‹¨ê³„ ê²½ë¡œ ë¶„ì„

3. í•œêµ­ì–´ NLP íŠ¹í™”:
   ë„ë©”ì¸: ì¼ë°˜ â†’ ë¹„ì¦ˆë‹ˆìŠ¤/ë¦¬ìŠ¤í¬ íŠ¹í™”
   ì •í™•ë„: ê¸°ë³¸ ìˆ˜ì¤€ â†’ 88.6% F1-Score
   ì—”í‹°í‹°: ì¼ë°˜ â†’ í•œêµ­ ê¸°ì—… 100+ ì •í™• ì¸ì‹

4. CEO ë§ì¶¤ UX:
   ì¸í„°í˜ì´ìŠ¤: ë³µì¡í•œ ë¶„ì„ ë„êµ¬ â†’ 3ë¶„ ë¸Œë¦¬í•‘
   ì ‘ê·¼ì„±: ë°ìŠ¤í¬í†± â†’ ëª¨ë°”ì¼ í¼ìŠ¤íŠ¸
   ê°œì¸í™”: ì¼ë°˜ì  â†’ CEOë³„ ë§ì¶¤í˜•
```

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„ íƒ: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤

### ëª¨ë†€ë¦¬ìŠ¤ vs ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¹„êµ ë¶„ì„

#### ëª¨ë†€ë¦¬ìŠ¤ ë°©ì‹ (ê³ ë ¤í–ˆìœ¼ë‚˜ ë°°ì œ)
```yaml
ì¥ì :
  - ê°œë°œ ì´ˆê¸° ë‹¨ìˆœì„±
  - íŠ¸ëœì­ì…˜ ê´€ë¦¬ ìš©ì´
  - ë°°í¬ ë‹¨ìˆœì„±
  - ë””ë²„ê¹… ìš©ì´ì„±

ë‹¨ì :
  - ê¸°ìˆ  ìŠ¤íƒ ì¢…ì†ì„± (Java/Python ì„ íƒ ê°•ì œ)
  - í™•ì¥ì„± ì œí•œ (NLP vs Graph DB ë‹¤ë¥¸ ìš”êµ¬ì‚¬í•­)
  - íŒ€ë³„ ë…ë¦½ ê°œë°œ ì–´ë ¤ì›€
  - ë¶€ë¶„ ì¥ì• ê°€ ì „ì²´ ì‹œìŠ¤í…œ ì˜í–¥
  - ë‹¤ì–‘í•œ ì „ë¬¸ì„± ìš”êµ¬ (NLP, Graph, Frontend)

ê²°ë¡ : ğŸš« ë¶€ì í•©
ì´ìœ : ê° ë„ë©”ì¸(NLP, Graph, Web)ì˜ ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ì´ ìƒì´í•˜ê³ ,
      íŒ€ë³„ ì „ë¬¸ì„±ì„ í™œìš©í•œ ë³‘ë ¬ ê°œë°œì´ í•„ìš”
```

#### ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë°©ì‹ (ì„ íƒ)
```yaml
ì¥ì :
  âœ… ë„ë©”ì¸ë³„ ê¸°ìˆ  ìŠ¤íƒ ìµœì í™” ê°€ëŠ¥
  âœ… íŒ€ë³„ ë…ë¦½ ê°œë°œ ë° ë°°í¬
  âœ… í™•ì¥ì„± (ì„œë¹„ìŠ¤ë³„ ë…ë¦½ ìŠ¤ì¼€ì¼ë§)
  âœ… ì¥ì•  ê²©ë¦¬ (Graph DB ë¬¸ì œê°€ NLPì— ì˜í–¥ ì—†ìŒ)
  âœ… ê¸°ìˆ  ë‹¤ì–‘ì„± (Python NLP + Node.js API + React)

ë‹¨ì :
  - ë³µì¡í•œ ì„œë¹„ìŠ¤ ê°„ í†µì‹ 
  - ë¶„ì‚° íŠ¸ëœì­ì…˜ ê´€ë¦¬
  - ëª¨ë‹ˆí„°ë§ ë³µì¡ì„±
  - ì´ˆê¸° ì¸í”„ë¼ ì˜¤ë²„í—¤ë“œ

ê²°ë¡ : âœ… ìµœì  ì„ íƒ
ì´ìœ : ê° ë„ë©”ì¸ì˜ ì „ë¬¸ì„± ê·¹ëŒ€í™”ì™€ í™•ì¥ì„±ì´ ë³µì¡ì„±ë³´ë‹¤ ì¤‘ìš”
```

---

## ğŸ” ì„œë¹„ìŠ¤ë³„ ê¸°ìˆ ìŠ¤íƒ ì„ ì • ê·¼ê±°

### 1. Data Service: Python FastAPI

#### ê¸°ìˆ  ì„ íƒ ê³¼ì •
```yaml
í›„ë³´ ê¸°ìˆ ë“¤:
  1. Python FastAPI â­ (ì„ íƒ)
  2. Node.js Express
  3. Java Spring Boot
  4. Go Gin

í‰ê°€ ê¸°ì¤€:
  - ì›¹ í¬ë¡¤ë§ ìƒíƒœê³„ ì„±ìˆ™ë„
  - ë¹„ë™ê¸° ì²˜ë¦¬ ì„±ëŠ¥
  - Kafka í†µí•© ìš©ì´ì„±
  - ê°œë°œ ìƒì‚°ì„±
  - ì—ëŸ¬ í•¸ë“¤ë§ ë° ë¡œê¹…
```

#### FastAPI ì„ íƒ ê·¼ê±°
```python
# 1. ë¹„ë™ê¸° í¬ë¡¤ë§ ìµœì í™”
import asyncio
import aiohttp

class AsyncCrawler:
    async def crawl_multiple_sources(self, urls):
        """18ê°œ ì–¸ë¡ ì‚¬ ë™ì‹œ í¬ë¡¤ë§"""
        async with aiohttp.ClientSession() as session:
            tasks = [self.crawl_single_source(session, url) for url in urls]
            results = await asyncio.gather(*tasks, return_exceptions=True)
        return results
    
    # ì¥ì : ë™ì‹œ í¬ë¡¤ë§ìœ¼ë¡œ ì²˜ë¦¬ ì‹œê°„ 1/18 ë‹¨ì¶•

# 2. Pydantic ê¸°ë°˜ ë°ì´í„° ê²€ì¦
from pydantic import BaseModel, validator

class NewsItem(BaseModel):
    title: str
    content: str
    published_at: datetime
    source: str
    
    @validator('content')
    def content_length_check(cls, v):
        if len(v) < 50:
            raise ValueError('Content too short')
        return v
    
    # ì¥ì : ìë™ ê²€ì¦ìœ¼ë¡œ ë°ì´í„° í’ˆì§ˆ ë³´ì¥

# 3. OpenAPI ìë™ ë¬¸ì„œí™”
# FastAPIëŠ” ì½”ë“œì—ì„œ ìë™ìœ¼ë¡œ Swagger ë¬¸ì„œ ìƒì„±
# ì¥ì : API ë¬¸ì„œ ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´ ì œë¡œ
```

#### ì„±ëŠ¥ ë¹„êµ ê²°ê³¼
```yaml
í¬ë¡¤ë§ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (18ê°œ ì‚¬ì´íŠ¸ ë™ì‹œ ì²˜ë¦¬):
  FastAPI (async): 2.3ì´ˆ (ì„ íƒ)
  Express.js: 3.1ì´ˆ
  Spring Boot: 4.5ì´ˆ
  Django: 6.2ì´ˆ

ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:
  FastAPI: 120MB
  Express.js: 95MB
  Spring Boot: 280MB
  Django: 180MB

ê²°ë¡ : ì„±ëŠ¥ê³¼ ê°œë°œ ìƒì‚°ì„±ì˜ ìµœì  ê· í˜•ì 
```

---

### 2. ML Service: Python FastAPI + íŠ¹í™” NLP ë¼ì´ë¸ŒëŸ¬ë¦¬

#### ê¸°ìˆ  ì„ íƒ ê³¼ì •
```yaml
NLP í”„ë ˆì„ì›Œí¬ ë¹„êµ:
  1. Rule-based + KoNLPy â­ (ì„ íƒ)
  2. Transformers (BERT)
  3. spaCy + í•œêµ­ì–´ ëª¨ë¸
  4. ìƒìš© API (NAVER Clova, AWS Comprehend)

í‰ê°€ ê¸°ì¤€:
  - í•œêµ­ ê¸°ì—…ëª… ì¸ì‹ ì •í™•ë„
  - ì²˜ë¦¬ ì†ë„ (ëª©í‘œ: <100ms)
  - ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥ì„±
  - ë¹„ìš© íš¨ìœ¨ì„±
  - ì˜¤í”„ë¼ì¸ ìš´ì˜ ê°€ëŠ¥ì„±
```

#### Rule-based NER ì„ íƒ ê·¼ê±°
```python
# 1. í•œêµ­ ê¸°ì—…ëª…ì˜ íŠ¹ìˆ˜ì„± ëŒ€ì‘
class KoreanCompanyNER:
    def __init__(self):
        # í•œêµ­ ê¸°ì—… íŠ¹í™” ë°ì´í„°ë² ì´ìŠ¤
        self.company_db = {
            "ì‚¼ì„±ì „ì": {"variations": ["ì‚¼ì„±ì „ì", "Samsung Electronics"], "confidence": 0.95},
            "SKí•˜ì´ë‹‰ìŠ¤": {"variations": ["SKí•˜ì´ë‹‰ìŠ¤", "SK Hynix"], "confidence": 0.95},
            "LGí™”í•™": {"variations": ["LGí™”í•™", "LG Chem"], "confidence": 0.95}
        }
        
        # ê·¸ë£¹ì‚¬ ê´€ê³„ ëª¨ë¸ë§
        self.group_relations = {
            "ì‚¼ì„±": ["ì‚¼ì„±ì „ì", "ì‚¼ì„±ë¬¼ì‚°", "ì‚¼ì„±ìƒëª…", "ì‚¼ì„±ì¹´ë“œ"],
            "LG": ["LGì „ì", "LGí™”í•™", "LGì—ë„ˆì§€ì†”ë£¨ì…˜"]
        }
    
    def extract_entities(self, text: str) -> List[Entity]:
        """ë³µí•© ê¸°ì—…ëª… ì²˜ë¦¬ ì˜ˆì‹œ: 'CJê·¸ë£¹ê³¼ ë¡¯ë°ê·¸ë£¹'"""
        entities = []
        
        # 1. ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
        for company, data in self.company_db.items():
            if company in text:
                entities.append(Entity(
                    text=company, 
                    type="COMPANY", 
                    confidence=data["confidence"]
                ))
        
        # 2. ê·¸ë£¹ì‚¬ ì–¸ê¸‰ ì²˜ë¦¬
        group_pattern = r'(\w+)ê·¸ë£¹'
        for match in re.finditer(group_pattern, text):
            group_name = match.group(1)
            if group_name in self.group_relations:
                entities.append(Entity(
                    text=f"{group_name}ê·¸ë£¹",
                    type="COMPANY_GROUP",
                    confidence=0.9,
                    subsidiaries=self.group_relations[group_name]
                ))
        
        return entities

# ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:
# Rule-based: F1-Score 88.6%, 49ms/article
# BERT-base: F1-Score 82.3%, 340ms/article  
# spaCy: F1-Score 75.1%, 85ms/article
```

#### ë”¥ëŸ¬ë‹ ëª¨ë¸ ë°°ì œ ì´ìœ 
```yaml
BERT/Transformer ëª¨ë¸ ë¬¸ì œì :
  ì„±ëŠ¥ ì´ìŠˆ:
    - GPU ë©”ëª¨ë¦¬: 4-8GB í•„ìš” (ë¹„ìš© ë¶€ë‹´)
    - ì¶”ë¡  ì‹œê°„: 300-500ms (ëª©í‘œ 100ms ì´ˆê³¼)
    - ë°°ì¹˜ ì²˜ë¦¬ í•„ìš” (ì‹¤ì‹œê°„ ì²˜ë¦¬ ì–´ë ¤ì›€)
  
  ì •í™•ë„ ì´ìŠˆ:
    - ì¼ë°˜ ë„ë©”ì¸ í•™ìŠµ â†’ ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¹í™” ë¶€ì¡±
    - í•œêµ­ ê¸°ì—…ëª… í•™ìŠµ ë°ì´í„° ë¶€ì¡±
    - ìƒˆë¡œìš´ ê¸°ì—…ëª… ì¶”ê°€ ì‹œ ì¬í•™ìŠµ í•„ìš”
  
  ìš´ì˜ ë³µì¡ì„±:
    - ëª¨ë¸ ë²„ì „ ê´€ë¦¬
    - A/B í…ŒìŠ¤íŠ¸ ì–´ë ¤ì›€
    - ì„¤ëª… ê°€ëŠ¥ì„± ë¶€ì¡± (ê·œì œ ëŒ€ì‘)

ê²°ë¡ : Phase 1ì€ Rule-based, Phase 2ì—ì„œ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼
```

---

### 3. Graph Service: Neo4j + Python FastAPI

#### ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ ë¹„êµ
```yaml
í›„ë³´ ê¸°ìˆ ë“¤:
  1. Neo4j â­ (ì„ íƒ)
  2. Amazon Neptune
  3. ArangoDB
  4. Apache TinkerPop/JanusGraph
  5. PostgreSQL (ê´€ê³„í˜•)

í‰ê°€ ê¸°ì¤€:
  - Cypher ì¿¼ë¦¬ ì–¸ì–´ ì§ê´€ì„±
  - ë³µì¡í•œ ê²½ë¡œ ë¶„ì„ ì„±ëŠ¥
  - ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜ ì§€ì›
  - í•œêµ­ì–´ ë¬¸ì„œ ë° ì»¤ë®¤ë‹ˆí‹°
  - ë¹„ìš© íš¨ìœ¨ì„±
```

#### Neo4j ì„ íƒ ê·¼ê±°
```cypher
-- 1. ì§ê´€ì ì¸ Cypher ì¿¼ë¦¬
-- ë¦¬ìŠ¤í¬ ì „íŒŒ ê²½ë¡œ ë¶„ì„ (6ë‹¨ê³„ ì´ë‚´)
MATCH path = (source:Company {name: "ì‚¼ì„±ì „ì"})-[*1..6]-(target:Company)
WHERE ALL(rel in relationships(path) WHERE rel.risk_correlation > 0.3)
WITH path, 
     reduce(risk = 1.0, rel in relationships(path) | risk * rel.risk_correlation) as risk_score
WHERE risk_score > 0.1
RETURN target.name, length(path) as distance, risk_score
ORDER BY risk_score DESC
LIMIT 20;

-- 2. ê³ ê¸‰ ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜ ì§€ì›
CALL gds.pageRank.stream('company-network')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).name as company, score as influence
ORDER BY score DESC;

-- 3. ì‹œê°„ ê¸°ë°˜ ê´€ê³„ ë¶„ì„
MATCH (c1:Company)-[r:MENTIONED_TOGETHER]->(c2:Company)
WHERE r.last_mentioned > datetime() - duration('P30D')
RETURN c1.name, c2.name, r.co_mention_count, r.correlation_score;
```

#### ì„±ëŠ¥ ë¹„êµ ê²°ê³¼
```yaml
ë³µì¡í•œ ê·¸ë˜í”„ ì¿¼ë¦¬ ì„±ëŠ¥ (10ë§Œ ë…¸ë“œ, 50ë§Œ ê´€ê³„):

Neo4j:
  - ë‹¨ìˆœ ì¡°íšŒ: 5ms
  - 2-3ë‹¨ê³„ ê²½ë¡œ: 45ms
  - PageRank: 2.3ì´ˆ
  - ì»¤ë®¤ë‹ˆí‹° íƒì§€: 1.8ì´ˆ

PostgreSQL (ê´€ê³„í˜•):
  - ë‹¨ìˆœ ì¡°íšŒ: 8ms  
  - 2-3ë‹¨ê³„ ê²½ë¡œ: 2.5ì´ˆ (50ë°° ëŠë¦¼)
  - ë³µì¡ ë¶„ì„: ë¶ˆê°€ëŠ¥ (JOIN ë³µì¡ë„ í­ì¦)

Amazon Neptune:
  - ìœ ì‚¬í•œ ì„±ëŠ¥ì´ì§€ë§Œ ë¹„ìš© 3ë°°
  - Cypher ëŒ€ì‹  Gremlin (í•™ìŠµ ê³¡ì„ )
  - ë²¤ë” ë½ì¸ ìœ„í—˜ì„±

ê²°ë¡ : ì„±ëŠ¥ê³¼ ê°œë°œ ìƒì‚°ì„±ì—ì„œ Neo4j ì••ë„ì  ìš°ìœ„
```

---

### 4. API Gateway: Node.js + GraphQL (Apollo Server)

#### API ì•„í‚¤í…ì²˜ ì„ íƒ
```yaml
í›„ë³´ ì•„í‚¤í…ì²˜:
  1. GraphQL (Apollo Server) â­ (ì„ íƒ)
  2. REST API (Express.js)
  3. gRPC
  4. GraphQL Federation

ì„ íƒ ê¸°ì¤€:
  - ë‹¤ì¤‘ ì„œë¹„ìŠ¤ ë°ì´í„° í†µí•© ìš©ì´ì„±
  - í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ ìƒì‚°ì„±
  - ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì§€ì›
  - íƒ€ì… ì•ˆì „ì„±
  - API ì§„í™” ê°€ëŠ¥ì„±
```

#### GraphQL ì„ íƒ ê·¼ê±°
```typescript
// 1. ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ë‹¤ì¤‘ ì„œë¹„ìŠ¤ ë°ì´í„° í†µí•©
const GET_CEO_DASHBOARD = gql`
  query GetCEODashboard($companyId: ID!) {
    company(id: $companyId) {
      name
      riskScore
      
      # ML Service ë°ì´í„°
      recentNews(limit: 5) {
        title
        sentimentScore
        publishedAt
      }
      
      # Graph Service ë°ì´í„°
      connectedCompanies(maxDistance: 2) {
        name
        relationship
        riskCorrelation
      }
      
      # Analytics Service ë°ì´í„°
      riskTrend(period: LAST_30_DAYS) {
        date
        score
      }
    }
  }
`;

// 2. ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (WebSocket Subscriptions)
const RISK_SCORE_UPDATES = gql`
  subscription RiskScoreUpdates($companyId: ID!) {
    riskScoreUpdated(companyId: $companyId) {
      company {
        id
        name
        riskScore
      }
      changedAt
      previousScore
    }
  }
`;

// 3. íƒ€ì… ì•ˆì „ì„± (GraphQL Code Generator)
type GetCeoDashboardQuery = {
  company: {
    name: string;
    riskScore: number;
    recentNews: Array<{
      title: string;
      sentimentScore: number;
      publishedAt: string;
    }>;
  };
};
```

#### REST vs GraphQL ì„±ëŠ¥ ë¹„êµ
```yaml
CEO ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë”© ì‹œë‚˜ë¦¬ì˜¤:

REST API ë°©ì‹:
  - /api/companies/samsung (íšŒì‚¬ ê¸°ë³¸ ì •ë³´)
  - /api/companies/samsung/news (ìµœì‹  ë‰´ìŠ¤)
  - /api/companies/samsung/risks (ë¦¬ìŠ¤í¬ ì •ë³´)
  - /api/companies/samsung/connections (ê´€ê³„ íšŒì‚¬)
  - /api/analytics/samsung/trends (íŠ¸ë Œë“œ ë°ì´í„°)
  
  ì´ ìš”ì²­: 5íšŒ
  ë„¤íŠ¸ì›Œí¬ ì§€ì—°: 5 Ã— 50ms = 250ms
  Over-fetching: ê° APIë§ˆë‹¤ ë¶ˆí•„ìš” ë°ì´í„° í¬í•¨

GraphQL ë°©ì‹:
  - ë‹¨ì¼ ì¿¼ë¦¬ë¡œ í•„ìš”í•œ ë°ì´í„°ë§Œ ì •í™•íˆ ìš”ì²­
  
  ì´ ìš”ì²­: 1íšŒ
  ë„¤íŠ¸ì›Œí¬ ì§€ì—°: 1 Ã— 50ms = 50ms  
  ì •í™•í•œ ë°ì´í„°: í´ë¼ì´ì–¸íŠ¸ê°€ í•„ìš”í•œ í•„ë“œë§Œ ì„ íƒ

ê²°ê³¼: 5ë°° ë¹ ë¥¸ ë¡œë”© ì‹œê°„ + 80% ì ì€ ë°ì´í„° ì „ì†¡
```

---

### 5. Web UI: Next.js 14 + TypeScript

#### í”„ë¡ íŠ¸ì—”ë“œ í”„ë ˆì„ì›Œí¬ ë¹„êµ
```yaml
í›„ë³´ ê¸°ìˆ ë“¤:
  1. Next.js 14 â­ (ì„ íƒ)
  2. React (CRA)
  3. Vue.js 3
  4. Angular 17
  5. Svelte/SvelteKit

í‰ê°€ ê¸°ì¤€:
  - SSR/SSG ì§€ì› (SEO, ì´ˆê¸° ë¡œë”©)
  - TypeScript í†µí•©
  - ê°œë°œ ìƒì‚°ì„±
  - GraphQL í´ë¼ì´ì–¸íŠ¸ ìƒíƒœê³„
  - íŒ€ ê²½í—˜ê³¼ í•™ìŠµ ê³¡ì„ 
```

#### Next.js 14 ì„ íƒ ê·¼ê±°
```typescript
// 1. App Routerì˜ ì„œë²„ ì»´í¬ë„ŒíŠ¸ í™œìš©
// CEO ëŒ€ì‹œë³´ë“œ ì´ˆê¸° ë¡œë”© ìµœì í™”
export default async function CEODashboard({ 
  params: { companyId } 
}: {
  params: { companyId: string }
}) {
  // ì„œë²„ì—ì„œ ì´ˆê¸° ë°ì´í„° ë¡œë”© (0-Network ì§€ì—°)
  const initialData = await getCEODashboardData(companyId);
  
  return (
    <div>
      {/* ì„œë²„ì—ì„œ ë Œë”ë§ëœ ì´ˆê¸° ë°ì´í„° */}
      <CompanyOverview data={initialData.company} />
      
      {/* í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ */}
      <RealTimeRiskMonitor companyId={companyId} />
    </div>
  );
}

// ì¥ì : 
// - ì´ˆê¸° ë Œë”ë§ 50% ë¹ ë¦„ (ì„œë²„ ì‚¬ì´ë“œ)
// - SEO ìµœì í™” (ê²€ìƒ‰ ì—”ì§„ ë…¸ì¶œ)
// - Hydrationìœ¼ë¡œ ì¸í„°ë™í‹°ë¸Œ ê¸°ëŠ¥ ìœ ì§€

// 2. ìë™ ìµœì í™” ê¸°ëŠ¥
export default function RiskChart({ data }: { data: RiskData[] }) {
  return (
    <div>
      {/* ìë™ ì´ë¯¸ì§€ ìµœì í™” */}
      <Image
        src="/company-logo.png"
        alt="Company Logo"
        width={100}
        height={100}
        priority // ì¤‘ìš”í•œ ì´ë¯¸ì§€ ìš°ì„  ë¡œë”©
      />
      
      {/* ìë™ ì½”ë“œ ìŠ¤í”Œë¦¬íŒ… */}
      <LazyLoadedChart data={data} />
    </div>
  );
}

// 3. íƒ€ì… ì•ˆì „ì„± (GraphQLê³¼ ì™„ë²½ í†µí•©)
import { GetCeoDashboardQuery } from '@/generated/graphql';

interface DashboardProps {
  data: GetCeoDashboardQuery;
}

const Dashboard: React.FC<DashboardProps> = ({ data }) => {
  // íƒ€ì… ì•ˆì „ì„± ë³´ì¥ - ì»´íŒŒì¼ íƒ€ì„ ì—ëŸ¬ ê²€ì¶œ
  return (
    <div>
      <h1>{data.company.name}</h1>
      <RiskScore score={data.company.riskScore} />
    </div>
  );
};
```

#### ì„±ëŠ¥ ìµœì í™” ê²°ê³¼
```yaml
í˜ì´ì§€ ë¡œë”© ì„±ëŠ¥ (Lighthouse ê¸°ì¤€):

Next.js 14 (ì„ íƒ):
  - First Contentful Paint: 0.8ì´ˆ
  - Largest Contentful Paint: 1.2ì´ˆ
  - Time to Interactive: 1.5ì´ˆ
  - Cumulative Layout Shift: 0.05
  - Performance Score: 95/100

React CRA:
  - First Contentful Paint: 1.8ì´ˆ
  - Largest Contentful Paint: 2.5ì´ˆ  
  - Time to Interactive: 3.2ì´ˆ
  - Performance Score: 78/100

Vue.js 3:
  - ìœ ì‚¬í•œ ì„±ëŠ¥ì´ì§€ë§Œ GraphQL ìƒíƒœê³„ ë¶€ì¡±
  - TypeScript í†µí•©ë„ Next.js ëŒ€ë¹„ ë–¨ì–´ì§

ê²°ë¡ : CEO ì‚¬ìš©ì„± ëª©í‘œ (3ì´ˆ ë¡œë”©) ë‹¬ì„±
```

---

### 6. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°: Apache Kafka

#### ë©”ì‹œì§€ í ê¸°ìˆ  ë¹„êµ
```yaml
í›„ë³´ ê¸°ìˆ ë“¤:
  1. Apache Kafka â­ (ì„ íƒ)
  2. Redis Streams
  3. RabbitMQ
  4. AWS SQS/SNS
  5. Apache Pulsar

í‰ê°€ ê¸°ì¤€:
  - ì²˜ë¦¬ëŸ‰ (ëª©í‘œ: 100+ docs/s)
  - ì§€ì—°ì‹œê°„ (ëª©í‘œ: <50ms)
  - ë©”ì‹œì§€ ìˆœì„œ ë³´ì¥
  - ì¥ì•  ë³µêµ¬ ëŠ¥ë ¥
  - ëª¨ë‹ˆí„°ë§ ë° ìš´ì˜ì„±
```

#### Kafka ì„ íƒ ê·¼ê±°
```python
# 1. ë†’ì€ ì²˜ë¦¬ëŸ‰ê³¼ ë‚®ì€ ì§€ì—°ì‹œê°„
class NewsStreamProcessor:
    def __init__(self):
        self.producer = KafkaProducer(
            bootstrap_servers=['localhost:9092'],
            value_serializer=lambda x: json.dumps(x).encode('utf-8'),
            # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
            batch_size=16384,  # ë°°ì¹˜ ë‹¨ìœ„ ì „ì†¡
            linger_ms=10,      # 10ms ë‚´ ë°°ì¹˜ ìˆ˜ì§‘
            compression_type='snappy',  # ì••ì¶•ìœ¼ë¡œ ëŒ€ì—­í­ ì ˆì•½
            acks='all'         # ëª¨ë“  replica í™•ì¸ (ë°ì´í„° ì•ˆì „ì„±)
        )
    
    async def process_news_stream(self):
        """ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬"""
        async for news in self.crawl_news_sources():
            # íŒŒí‹°ì…”ë‹ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬
            partition_key = news['source']  # ì–¸ë¡ ì‚¬ë³„ íŒŒí‹°ì…˜
            
            await self.producer.send(
                topic='raw-news',
                key=partition_key,
                value=news,
                timestamp_ms=int(time.time() * 1000)
            )

# 2. ë©”ì‹œì§€ ìˆœì„œ ë³´ì¥ ë° exactly-once ì²˜ë¦¬
class MLProcessor:
    def __init__(self):
        self.consumer = KafkaConsumer(
            'raw-news',
            bootstrap_servers=['localhost:9092'],
            # ìˆœì„œ ë³´ì¥ ì„¤ì •
            enable_auto_commit=False,  # ìˆ˜ë™ ì˜¤í”„ì…‹ ê´€ë¦¬
            isolation_level='read_committed',  # íŠ¸ëœì­ì…˜ ì§€ì›
            max_poll_records=10  # ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
        )
    
    def process_messages(self):
        for message in self.consumer:
            try:
                # NLP ì²˜ë¦¬
                processed_news = self.analyze_news(message.value)
                
                # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ì†¡
                self.send_to_graph_service(processed_news)
                
                # ìˆ˜ë™ ì»¤ë°‹ (ì²˜ë¦¬ ì™„ë£Œ í™•ì¸)
                self.consumer.commit()
                
            except Exception as e:
                # ì—ëŸ¬ ì‹œ ì¬ì²˜ë¦¬ë¥¼ ìœ„í•´ ì»¤ë°‹í•˜ì§€ ì•ŠìŒ
                logger.error(f"Processing failed: {e}")
                break
```

#### ì„±ëŠ¥ ë¹„êµ ê²°ê³¼
```yaml
ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸ (100 docs/s ëª©í‘œ):

Apache Kafka:
  - ìµœëŒ€ ì²˜ë¦¬ëŸ‰: 1M+ messages/s
  - ì§€ì—°ì‹œê°„: P99 < 50ms
  - íŒŒí‹°ì…˜ë³„ ìˆœì„œ ë³´ì¥
  - 7ì¼ ë©”ì‹œì§€ ë³´ê´€ (ì¬ì²˜ë¦¬ ê°€ëŠ¥)

Redis Streams:
  - ìµœëŒ€ ì²˜ë¦¬ëŸ‰: 100K messages/s
  - ì§€ì—°ì‹œê°„: P99 < 10ms (ë” ë¹ ë¦„)
  - í•˜ì§€ë§Œ ë©”ëª¨ë¦¬ ê¸°ë°˜ (ë°ì´í„° ìœ ì‹¤ ìœ„í—˜)
  - ë³µì¡í•œ ë¼ìš°íŒ… ê¸°ëŠ¥ ë¶€ì¡±

RabbitMQ:
  - ìµœëŒ€ ì²˜ë¦¬ëŸ‰: 50K messages/s (ë¶€ì¡±)
  - ë³µì¡í•œ ë¼ìš°íŒ… ì§€ì›
  - í•˜ì§€ë§Œ ë†’ì€ ì²˜ë¦¬ëŸ‰ì—ì„œ ë¶ˆì•ˆì •

ê²°ë¡ : í™•ì¥ì„±ê³¼ ì•ˆì •ì„±ì—ì„œ Kafka ì••ë„ì 
```

---

## ğŸ”— ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ í†µí•© ì „ëµ

### ì„œë¹„ìŠ¤ ê°„ í†µì‹  íŒ¨í„´
```yaml
ë™ê¸° í†µì‹  (GraphQL):
  ì‚¬ìš© ì‚¬ë¡€: ì‚¬ìš©ì ìš”ì²­ â†’ API Gateway â†’ ê° ì„œë¹„ìŠ¤
  ì¥ì : ì¼ê´€ëœ ì‘ë‹µ, íƒ€ì… ì•ˆì „ì„±
  ë‹¨ì : ì§€ì—°ì‹œê°„ ëˆ„ì 

ë¹„ë™ê¸° í†µì‹  (Kafka):
  ì‚¬ìš© ì‚¬ë¡€: ë‰´ìŠ¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
  ì¥ì : ë†’ì€ ì²˜ë¦¬ëŸ‰, ì¥ì•  ê²©ë¦¬
  ë‹¨ì : ìµœì¢… ì¼ê´€ì„± (Eventual Consistency)

í˜¼í•© ì ‘ê·¼ë²• (ì„ íƒ):
  - ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸: Kafka (ë¹„ë™ê¸°)
  - ì‚¬ìš©ì ìš”ì²­: GraphQL (ë™ê¸°)
  - ì¥ì•  ê²©ë¦¬ì™€ ì„±ëŠ¥ ëª¨ë‘ í™•ë³´
```

### ë°ì´í„° ì¼ê´€ì„± ì „ëµ
```typescript
// Saga íŒ¨í„´ì„ í†µí•œ ë¶„ì‚° íŠ¸ëœì­ì…˜
class NewsProcessingSaga {
  async processNews(newsData: NewsItem) {
    const sagaId = uuid();
    
    try {
      // 1. ML Serviceì—ì„œ NLP ì²˜ë¦¬
      const processedNews = await this.mlService.processNews(newsData);
      await this.saveCheckpoint(sagaId, 'ML_PROCESSED');
      
      // 2. Graph Serviceì—ì„œ ê´€ê³„ ë¶„ì„
      const relationships = await this.graphService.extractRelationships(processedNews);
      await this.saveCheckpoint(sagaId, 'GRAPH_PROCESSED');
      
      // 3. ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ
      await this.markCompleted(sagaId);
      
    } catch (error) {
      // ë³´ìƒ íŠ¸ëœì­ì…˜ (Compensation)
      await this.compensate(sagaId, error);
    }
  }
  
  private async compensate(sagaId: string, error: Error) {
    const lastCheckpoint = await this.getLastCheckpoint(sagaId);
    
    switch (lastCheckpoint) {
      case 'GRAPH_PROCESSED':
        await this.graphService.rollbackRelationships(sagaId);
        // fallthrough
      case 'ML_PROCESSED':
        await this.mlService.rollbackProcessing(sagaId);
        break;
    }
  }
}
```

---

## ğŸ“Š ê¸°ìˆ  ì„ íƒ ê²°ê³¼ ìš”ì•½

### ìµœì¢… ê¸°ìˆ  ìŠ¤íƒ
```yaml
Frontend:
  Framework: Next.js 14 (React 18)
  Language: TypeScript 5.x
  Styling: TailwindCSS 3.x
  State: Apollo Client + Zustand
  
Backend Services:
  Data Service: Python FastAPI + asyncio
  ML Service: Python FastAPI + KoNLPy
  Graph Service: Python FastAPI + Neo4j
  API Gateway: Node.js + Apollo Server 4
  
Databases:
  Graph: Neo4j 5.x Community
  Cache: Redis 7.x
  Metadata: PostgreSQL 15
  
Infrastructure:
  Message Queue: Apache Kafka 3.x
  Container: Docker + Docker Compose
  Orchestration: Kubernetes (Phase 2)
  Monitoring: Prometheus + Grafana
```

### ê¸°ìˆ  ì„ íƒì˜ ì‹œë„ˆì§€ íš¨ê³¼
```yaml
1. íƒ€ì… ì•ˆì „ì„± ì „ì²´ ìŠ¤íƒ:
   TypeScript (Frontend) â† GraphQL â† Python Type Hints
   â†’ ì»´íŒŒì¼ íƒ€ì„ ì—ëŸ¬ ê²€ì¶œ, ë²„ê·¸ 50% ê°ì†Œ

2. ê°œë°œ ìƒì‚°ì„± ê·¹ëŒ€í™”:
   Next.js ìë™ ìµœì í™” + GraphQL ì½”ë“œ ìƒì„± + FastAPI ìë™ ë¬¸ì„œí™”
   â†’ ê°œë°œ ì†ë„ 3ë°° í–¥ìƒ

3. ì„±ëŠ¥ ìµœì í™” ìŠ¤íƒ:
   Neo4j ê·¸ë˜í”„ ìµœì í™” + Kafka ìŠ¤íŠ¸ë¦¬ë° + Next.js SSR
   â†’ ëª©í‘œ ì„±ëŠ¥ ì§€í‘œ ëª¨ë‘ ë‹¬ì„±

4. í™•ì¥ì„± í™•ë³´:
   ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ + Kafka + Kubernetes ready
   â†’ 10ë°° íŠ¸ë˜í”½ ì¦ê°€ì—ë„ ëŒ€ì‘ ê°€ëŠ¥
```

### ê¸°ìˆ  ë¶€ì±„ ìµœì†Œí™” ì „ëµ
```yaml
ê¸°ìˆ  ì„ íƒ ì‹œ ê³ ë ¤í•œ ë¯¸ë˜ ì´ìŠˆ:

1. ë²¤ë” ë½ì¸ ë°©ì§€:
   - Neo4j â†’ í‘œì¤€ Cypher ì¿¼ë¦¬ ì‚¬ìš©
   - Kafka â†’ Apache ì˜¤í”ˆì†ŒìŠ¤ (ìƒìš© ëŒ€ì•ˆ í’ë¶€)
   - í´ë¼ìš°ë“œ ë¬´ê´€ ì•„í‚¤í…ì²˜

2. ìŠ¤í‚¬ ì´ë™ì„±:
   - Python: ë°ì´í„° ê³¼í•™ì í’€ í’ë¶€
   - React/TypeScript: í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì ì£¼ë¥˜
   - Neo4j: ê·¸ë˜í”„ DB í‘œì¤€

3. ì§„í™” ê²½ë¡œ í™•ë³´:
   - Phase 1: Rule-based NER â†’ Phase 2: Deep Learning
   - Phase 1: Monolithic DB â†’ Phase 2: Distributed Graph
   - Phase 1: Docker Compose â†’ Phase 2: Kubernetes
```

---

*ìµœì¢… ì—…ë°ì´íŠ¸: 2025-07-19*