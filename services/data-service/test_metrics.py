#!/usr/bin/env python3
"""
ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import asyncio
import requests
import time
from datetime import datetime

async def test_metrics():
    """ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸"""
    base_url = "http://localhost:8001"
    
    print("=== Data Service ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸ ===\n")
    
    # 1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    try:
        health = requests.get(f"{base_url}/health")
        print(f"1. Health Check: {health.json()}")
    except Exception as e:
        print(f"âŒ Health check failed: {e}")
        return
    
    # 2. ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    print("\n2. ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘...")
    try:
        response = requests.post(f"{base_url}/api/v1/scheduler/start")
        print(f"   Response: {response.json()}")
    except Exception as e:
        print(f"âŒ Scheduler start failed: {e}")
    
    # 3. ì ì‹œ ëŒ€ê¸° (í¬ë¡¤ë§ì´ ì§„í–‰ë˜ë„ë¡)
    print("\n3. í¬ë¡¤ë§ ì§„í–‰ ì¤‘... (30ì´ˆ ëŒ€ê¸°)")
    await asyncio.sleep(30)
    
    # 4. ë©”íŠ¸ë¦­ í™•ì¸
    print("\n4. Prometheus ë©”íŠ¸ë¦­ í™•ì¸:")
    try:
        metrics = requests.get(f"{base_url}/metrics")
        if metrics.status_code == 200:
            # ë©”íŠ¸ë¦­ ë‚´ìš© ì¼ë¶€ë§Œ ì¶œë ¥
            lines = metrics.text.split('\n')
            for line in lines:
                if line and not line.startswith('#'):
                    if any(keyword in line for keyword in [
                        'data_service_crawl_requests_total',
                        'data_service_articles_processed_total',
                        'data_service_kafka_messages_sent_total',
                        'data_service_current_throughput_articles_per_hour',
                        'data_service_deduplication_rate'
                    ]):
                        print(f"   {line}")
        else:
            print(f"âŒ Metrics endpoint returned {metrics.status_code}")
    except Exception as e:
        print(f"âŒ Metrics fetch failed: {e}")
    
    # 5. ë©”íŠ¸ë¦­ í†µê³„ í™•ì¸
    print("\n5. ë©”íŠ¸ë¦­ í†µê³„:")
    try:
        stats = requests.get(f"{base_url}/api/v1/metrics/stats")
        if stats.status_code == 200:
            data = stats.json()
            print(f"   Uptime: {data.get('uptime_seconds', 0):.1f} seconds")
            print(f"   Article counts: {data.get('article_counts', {})}")
            print(f"   Duplicate counts: {data.get('duplicate_counts', {})}")
            print(f"   Deduplication rates: {data.get('deduplication_rates', {})}")
    except Exception as e:
        print(f"âŒ Metrics stats failed: {e}")
    
    # 6. ìŠ¤ì¼€ì¤„ëŸ¬ í†µê³„ í™•ì¸
    print("\n6. ìŠ¤ì¼€ì¤„ëŸ¬ í†µê³„:")
    try:
        scheduler_stats = requests.get(f"{base_url}/api/v1/scheduler/stats")
        if scheduler_stats.status_code == 200:
            data = scheduler_stats.json()
            print(f"   Total crawls: {data.get('total_crawls', 0)}")
            print(f"   Successful crawls: {data.get('successful_crawls', 0)}")
            print(f"   Failed crawls: {data.get('failed_crawls', 0)}")
            print(f"   Total articles: {data.get('total_articles', 0)}")
            print(f"   Throughput: {data.get('throughput_per_hour', 0):.1f} articles/hour")
            print(f"   Average latency: {data.get('average_latency', 0):.1f} seconds")
            print(f"   Running tasks: {data.get('running_tasks', [])}")
    except Exception as e:
        print(f"âŒ Scheduler stats failed: {e}")
    
    # 7. íƒœìŠ¤í¬ ìƒíƒœ í™•ì¸
    print("\n7. ìŠ¤ì¼€ì¤„ëŸ¬ íƒœìŠ¤í¬ ìƒíƒœ:")
    try:
        tasks = requests.get(f"{base_url}/api/v1/scheduler/tasks")
        if tasks.status_code == 200:
            data = tasks.json()
            for task in data.get('tasks', []):
                print(f"   - {task['source_id']}: "
                      f"running={task.get('is_running', False)}, "
                      f"failures={task.get('consecutive_failures', 0)}")
    except Exception as e:
        print(f"âŒ Scheduler tasks failed: {e}")
    
    # 8. ë‹¤ì‹œ ë©”íŠ¸ë¦­ í™•ì¸ (ë³€í™” ê´€ì°°)
    print("\n8. ì¶”ê°€ í¬ë¡¤ë§ í›„ ë©”íŠ¸ë¦­ ì¬í™•ì¸ (30ì´ˆ ëŒ€ê¸°)...")
    await asyncio.sleep(30)
    
    try:
        metrics = requests.get(f"{base_url}/metrics")
        if metrics.status_code == 200:
            lines = metrics.text.split('\n')
            print("\n   ì£¼ìš” ë©”íŠ¸ë¦­ í˜„í™©:")
            for line in lines:
                if line and not line.startswith('#'):
                    if 'data_service_crawl_requests_total' in line and 'success' in line:
                        print(f"   âœ… {line}")
                    elif 'data_service_articles_processed_total' in line and 'processed' in line:
                        print(f"   ğŸ“„ {line}")
                    elif 'data_service_current_throughput_articles_per_hour' in line:
                        print(f"   ğŸ“Š {line}")
    except Exception as e:
        print(f"âŒ Final metrics check failed: {e}")
    
    # 9. ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€
    print("\n9. ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€...")
    try:
        response = requests.post(f"{base_url}/api/v1/scheduler/stop")
        print(f"   Response: {response.json()}")
    except Exception as e:
        print(f"âŒ Scheduler stop failed: {e}")
    
    print("\n=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")


if __name__ == "__main__":
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now()}")
    asyncio.run(test_metrics())
    print(f"\nì¢…ë£Œ ì‹œê°„: {datetime.now()}")