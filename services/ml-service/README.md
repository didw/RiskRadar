# ML Service
# ë¨¸ì‹ ëŸ¬ë‹/ìì—°ì–´ì²˜ë¦¬ ì„œë¹„ìŠ¤

## ğŸ¯ ì„œë¹„ìŠ¤ ê°œìš”

ML ServiceëŠ” RiskRadar í”Œë«í¼ì˜ ì¸ê³µì§€ëŠ¥ ì—”ì§„ì…ë‹ˆë‹¤. í•œêµ­ì–´ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ê¸°ì—… ë¦¬ìŠ¤í¬ì™€ ê´€ë ¨ëœ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
- ğŸ¢ **ê°œì²´ëª… ì¸ì‹ (NER)**: ê¸°ì—…, ì¸ë¬¼, ì´ë²¤íŠ¸ ë“± í•µì‹¬ ì—”í‹°í‹° ì¶”ì¶œ
- ğŸ˜Š **ê°ì • ë¶„ì„**: ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ê°ì • ë¶„ë¥˜
- âš ï¸ **ë¦¬ìŠ¤í¬ ì ìˆ˜**: ê¸°ì—…ë³„ ë¦¬ìŠ¤í¬ ë ˆë²¨ ê³„ì‚°
- ğŸ”‘ **í‚¤ì›Œë“œ ì¶”ì¶œ**: í•µì‹¬ í‚¤ì›Œë“œ ë° í† í”½ ë¶„ì„
- ğŸš€ **ê³ ì„±ëŠ¥ ì²˜ë¦¬**: ë°°ì¹˜ ì²˜ë¦¬ ë° ìºì‹±ìœ¼ë¡œ ìµœì í™”

### ì„±ëŠ¥ ì§€í‘œ (Sprint 1 - Week 2 ê¸°ì¤€)
- âš¡ **ì²˜ë¦¬ ì†ë„**: 2.57ms/article (ëª©í‘œ: 10ms) âœ…
- ğŸ“Š **ì²˜ë¦¬ëŸ‰**: 389 docs/second (ëª©í‘œ: 100 docs/s) âœ…
- ğŸ¯ **NER F1-Score**: 56.3% (ëª©í‘œ: 80%) âš ï¸ **ê°œì„  ì¤‘**
- ğŸ’¾ **ìºì‹œ íš¨ê³¼**: 90%+ ì„±ëŠ¥ í–¥ìƒ (ë°˜ë³µ ìš”ì²­)
- ğŸ³ **Docker ì´ë¯¸ì§€**: 2GB ì ˆê° (CPU ì „ìš© PyTorch)

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### Prerequisites
- Python 3.11+
- Java 11+ (KoNLPy ì‚¬ìš© ì‹œ)
- CUDA 11.8+ (GPU ì‚¬ìš© ì‹œ)
- Docker & Docker Compose

### ì„¤ì¹˜ ë° ì‹¤í–‰
```bash
# 1. Java ì„¤ì¹˜ (Ubuntu/Debian)
sudo apt-get install openjdk-11-jdk

# 2. ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜ (ê²½ëŸ‰ ë²„ì „)
pip install -r requirements.txt

# 3. ML ì˜ì¡´ì„± ì„¤ì¹˜ (ì„ íƒì‚¬í•­ - ì „ì²´ ê¸°ëŠ¥ ì‚¬ìš© ì‹œ)
pip install -r requirements-ml.txt

# 4. í™˜ê²½ ì„¤ì •
cp .env.example .env

# 5. ì„œë¹„ìŠ¤ ì‹¤í–‰
python -m uvicorn src.main:app --host 0.0.0.0 --port 8082

# ë˜ëŠ” Docker ì‚¬ìš© (ê°œë°œ/í…ŒìŠ¤íŠ¸)
docker build -t ml-service .
docker run -p 8082:8082 ml-service

# Docker Compose ì‚¬ìš©
docker-compose up ml-service
```

### ì˜ì¡´ì„± ê´€ë¦¬
- `requirements.txt`: ê¸°ë³¸ ì˜ì¡´ì„± (ë¹ ë¥¸ ë¹Œë“œ)
- `requirements-ml.txt`: ML í”„ë ˆì„ì›Œí¬ (torch, transformers)

## ğŸ“Š API ì—”ë“œí¬ì¸íŠ¸

### Health Check
```bash
GET /api/v1/health
```

### í…ìŠ¤íŠ¸ ì²˜ë¦¬
```bash
POST /api/v1/process
{
  "text": "ì‚¼ì„±ì „ìê°€ ë°˜ë„ì²´ ê³µì¥ì„ ì¦ì„¤í•œë‹¤ê³  ë°œí‘œí–ˆë‹¤."
}
```

### ë°°ì¹˜ ì²˜ë¦¬
```bash
POST /api/v1/batch
{
  "texts": ["í…ìŠ¤íŠ¸1", "í…ìŠ¤íŠ¸2", ...]
}
```

### ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰
```bash
GET /api/v1/knowledge-base/search?query=ì‚¼ì„±&entity_type=COMPANY
```

### ìºì‹œ í†µê³„
```bash
GET /api/v1/cache/stats
```

## ğŸ”§ ì„¤ì •

### í™˜ê²½ ë³€ìˆ˜
```env
# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_CONSUMER_GROUP=ml-service

# Model
MODEL_PATH=/models
MODEL_VERSION=v1.0.0

# GPU
CUDA_VISIBLE_DEVICES=0
```

## ğŸ“ ë°ì´í„° í¬ë§·

### Input Schema (Kafka)
```json
{
  "id": "news-id",
  "title": "ë‰´ìŠ¤ ì œëª©",
  "content": "ë‰´ìŠ¤ ë³¸ë¬¸",
  "source": "chosun",
  "published_at": "2024-01-15T10:00:00Z"
}
```

### Output Schema (Kafka)
```json
{
  "original": {
    "id": "news-id",
    "title": "ë‰´ìŠ¤ ì œëª©"
  },
  "nlp": {
    "entities": [
      {
        "text": "ì‚¼ì„±ì „ì",
        "type": "COMPANY",
        "confidence": 0.95
      }
    ],
    "sentiment": {
      "label": "positive",
      "score": 0.8
    },
    "keywords": ["ë°˜ë„ì²´", "íˆ¬ì", "ê³µì¥"],
    "risk_score": 3.5
  },
  "processed_at": "2024-01-15T10:05:00Z"
}
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
pytest tests/unit/

# ëª¨ë¸ í…ŒìŠ¤íŠ¸
pytest tests/models/

# í†µí•© í…ŒìŠ¤íŠ¸
pytest tests/integration/

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
python tests/performance/benchmark.py
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§

### Prometheus Metrics
- `ml_inference_duration_seconds`: ì¶”ë¡  ì‹œê°„
- `ml_processed_total`: ì²˜ë¦¬ëœ ë¬¸ì„œ ìˆ˜
- `ml_model_accuracy`: ëª¨ë¸ ì •í™•ë„

### GPU ëª¨ë‹ˆí„°ë§
```bash
# GPU ì‚¬ìš©ë¥  í™•ì¸
nvidia-smi

# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi
```

## ğŸ§  ëª¨ë¸ ì •ë³´

### ì‚¬ìš© ëª¨ë¸
- **NER**: 
  - KoELECTRA Naver NER (í˜„ì¬) - F1: 56.3%
  - KLUE-BERT (ê³„íšì¤‘) - ëª©í‘œ F1: 80%
- **Sentiment**: ê·œì¹™ ê¸°ë°˜ ê°ì • ë¶„ì„
- **Keywords**: TF-IDF ê¸°ë°˜ ì¶”ì¶œ  
- **Risk Score**: ê°ì • ë° í‚¤ì›Œë“œ ê¸°ë°˜ ê³„ì‚°

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸ (Sprint 1 - Week 2 êµ¬í˜„ ì™„ë£Œ)
- **KoreanNERPostProcessor**: í•œêµ­ì–´ íŠ¹í™” í›„ì²˜ë¦¬ (ì¡°ì‚¬ ì œê±°)
- **KoreanEntityLinker**: ì§€ì‹ë² ì´ìŠ¤ ê¸°ë°˜ ì—”í‹°í‹° ë§í‚¹ (40+ ê¸°ì—…/ì¸ë¬¼)
- **KoreanEntitySplitter**: ì—°ê²°ì‚¬ ì—”í‹°í‹° ë¶„ë¦¬ ("ì‚¼ì„±ê³¼ LG" â†’ ["ì‚¼ì„±", "LG"])
- **NERCacheManager**: LRU ìºì‹± ì‹œìŠ¤í…œ (ëª¨ë¸ ë¡œë”©, ì¶”ë¡  ê²°ê³¼)
- **AdaptiveBatchProcessor**: ë™ì  ë°°ì¹˜ ì²˜ë¦¬ (1-32 ë°°ì¹˜ í¬ê¸°)

### ë‹¤ìŒ Sprint ê³„íš
1. **F1-Score ê°œì„ ** (ìš°ì„ ìˆœìœ„ 1)
   - KLUE-BERT ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° í†µí•©
   - ë„ë©”ì¸ íŠ¹í™” ë°ì´í„°ì…‹ êµ¬ì¶•
2. **ì‹¤ì œ Kafka í†µí•©** (Mock â†’ Real mode)
3. **ê°ì • ë¶„ì„ ëª¨ë¸ ê³ ë„í™”**

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [ê°œë°œ ê°€ì´ë“œë¼ì¸](CLAUDE.md)
- [ë³€ê²½ ì´ë ¥](CHANGELOG.md)
- [ëª¨ë¸ í•™ìŠµ ê°€ì´ë“œ](docs/training.md)
- [API ìƒì„¸ ë¬¸ì„œ](docs/api.md)

## ğŸ¤ ë‹´ë‹¹ì

- **Squad**: ML/NLP Squad
- **Lead**: @ml-lead
- **Members**: @ml-member1, @ml-member2, @ml-member3