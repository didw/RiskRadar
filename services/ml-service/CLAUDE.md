# ML Service Development Guidelines
# ML/NLP ì„œë¹„ìŠ¤ ê°œë°œ ê°€ì´ë“œë¼ì¸

## ğŸ“‹ ì„œë¹„ìŠ¤ ê°œìš”

ML ServiceëŠ” RiskRadarì˜ ìì—°ì–´ ì²˜ë¦¬ ë° ë¨¸ì‹ ëŸ¬ë‹ ì¶”ë¡ ì„ ë‹´ë‹¹í•˜ëŠ” ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. í•œêµ­ì–´ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•˜ê³ , ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ë©°, ë¦¬ìŠ¤í¬ ê´€ë ¨ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ml-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/             # ML ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ ner/           # ê°œì²´ëª… ì¸ì‹
â”‚   â”‚   â”‚   â”œâ”€â”€ kobert_ner.py
â”‚   â”‚   â”‚   â””â”€â”€ configs/
â”‚   â”‚   â”œâ”€â”€ sentiment/     # ê°ì • ë¶„ì„
â”‚   â”‚   â”‚   â””â”€â”€ sentiment_analyzer.py
â”‚   â”‚   â””â”€â”€ risk/          # ë¦¬ìŠ¤í¬ ë¶„ë¥˜
â”‚   â”‚       â””â”€â”€ risk_classifier.py
â”‚   â”œâ”€â”€ processors/        # NLP ì „ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ tokenizer.py   # í•œêµ­ì–´ í† í¬ë‚˜ì´ì €
â”‚   â”‚   â”œâ”€â”€ normalizer.py  # í…ìŠ¤íŠ¸ ì •ê·œí™”
â”‚   â”‚   â””â”€â”€ pipeline.py    # ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ kafka/             # Kafka ì—°ë™
â”‚   â”‚   â”œâ”€â”€ consumer.py
â”‚   â”‚   â”œâ”€â”€ producer.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ api/              # REST API
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â””â”€â”€ config.py         # ì„¤ì •
â”œâ”€â”€ models/               # í•™ìŠµëœ ëª¨ë¸ íŒŒì¼
â”‚   â”œâ”€â”€ kobert-ner/
â”‚   â””â”€â”€ sentiment/
â”œâ”€â”€ tests/                # í…ŒìŠ¤íŠ¸
â”œâ”€â”€ notebooks/            # ì‹¤í—˜ ë…¸íŠ¸ë¶
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ CLAUDE.md            # í˜„ì¬ íŒŒì¼
â””â”€â”€ CHANGELOG.md
```

## ğŸ’» ê°œë°œ í™˜ê²½ ì„¤ì •

### Prerequisites
```bash
Python 3.11+
CUDA 11.8+ (GPU ì‚¬ìš© ì‹œ)
Poetry ë˜ëŠ” pip
Docker
```

### ì„¤ì¹˜
```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate

# ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜ (ë¹ ë¥¸ ì‹œì‘)
pip install -r requirements.txt

# ML í”„ë ˆì„ì›Œí¬ ì„¤ì¹˜ (ì „ì²´ ê¸°ëŠ¥)
pip install -r requirements-ml.txt

# ë˜ëŠ” GPU ë²„ì „ ì„¤ì¹˜
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install transformers

# í•œêµ­ì–´ NLP ë„êµ¬ ì„¤ì¹˜
python -m konlpy.downloader all
```

### Docker ë¹Œë“œ
```bash
# ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© (ê²½ëŸ‰)
docker build -t ml-service .

# í”„ë¡œë•ì…˜ìš© (ML í¬í•¨)
docker build -f Dockerfile.prod -t ml-service:prod .
```

### ë¡œì»¬ ì‹¤í–‰
```bash
# ì„œë¹„ìŠ¤ ì‹¤í–‰
python -m src.main

# ë˜ëŠ” ê°œë°œ ëª¨ë“œ
uvicorn src.main:app --reload --port 8002
```

## ğŸ”§ ì£¼ìš” ì»´í¬ë„ŒíŠ¸

### 1. NLP Pipeline
```python
class NLPPipeline:
    """í•œêµ­ì–´ NLP ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.tokenizer = SimpleTokenizer()  # Java ë¯¸ì„¤ì¹˜ í™˜ê²½
        self.ner_model = KoElectraNaverNERModel()  # ìµœì‹  ëª¨ë¸
        self.sentiment_analyzer = SentimentAnalyzer()
        self.keyword_extractor = KeywordExtractor()
        
    async def process(self, text: str) -> ProcessedResult:
        """í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        # 1. ì „ì²˜ë¦¬
        normalized = normalize_text(text)
        
        # 2. í† í°í™”
        tokens = self.tokenizer.tokenize(normalized)
        
        # 3. NER (ìºì‹± ì§€ì›)
        entities = self.ner_model.extract_entities(text)
        
        # 4. ê°ì • ë¶„ì„
        sentiment = self.sentiment_analyzer.analyze(text)
        
        # 5. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.keyword_extractor.extract(tokens)
        
        # 6. ë¦¬ìŠ¤í¬ ì ìˆ˜
        risk_score = calculate_risk_score(sentiment, keywords)
        
        return ProcessedResult(
            entities=entities,
            sentiment=sentiment,
            keywords=keywords,
            risk_score=risk_score
        )
```

### 2. Entity Extraction
```python
class EntityExtractor:
    """ê°œì²´ëª… ì¸ì‹"""
    
    def __init__(self, model_path: str):
        self.model = KoBERTForNER.from_pretrained(model_path)
        self.label_map = {
            0: "O",
            1: "B-COMPANY",
            2: "I-COMPANY",
            3: "B-PERSON",
            4: "I-PERSON",
            # ...
        }
    
    async def extract(self, tokens: List[str]) -> List[Entity]:
        """ì—”í‹°í‹° ì¶”ì¶œ"""
        # ì¸ì½”ë”©
        inputs = self.tokenizer.encode_plus(tokens, return_tensors="pt")
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = self.model(**inputs)
            predictions = torch.argmax(outputs.logits, dim=-1)
        
        # ë””ì½”ë”©
        entities = self.decode_predictions(tokens, predictions)
        return entities
```

### 3. Kafka Integration
```python
class MLConsumer:
    """Kafka ì»¨ìŠˆë¨¸"""
    
    def __init__(self):
        self.consumer = KafkaConsumer(
            'raw-news',
            bootstrap_servers=KAFKA_SERVERS,
            value_deserializer=lambda m: json.loads(m.decode('utf-8'))
        )
        self.producer = MLProducer()
        self.pipeline = NLPPipeline()
    
    async def process_messages(self):
        """ë©”ì‹œì§€ ì²˜ë¦¬ ë£¨í”„"""
        for message in self.consumer:
            try:
                # ì›ë³¸ ë‰´ìŠ¤
                news = message.value
                
                # NLP ì²˜ë¦¬
                result = await self.pipeline.process(news['content'])
                
                # ê²°ê³¼ ë°œí–‰
                enriched = {
                    "original": news,
                    "nlp": result.dict(),
                    "processed_at": datetime.now().isoformat()
                }
                
                await self.producer.send_enriched(enriched)
                
            except Exception as e:
                logger.error(f"Processing failed: {e}")
                # DLQë¡œ ì „ì†¡
```

## ğŸ“ ì½”ë”© ê·œì¹™

### 1. ëª¨ë¸ ê´€ë¦¬
- ëª¨ë¸ ë²„ì „ ê´€ë¦¬ (DVC ì‚¬ìš©)
- ëª¨ë¸ ë©”íƒ€ë°ì´í„° ê¸°ë¡
- A/B í…ŒìŠ¤íŠ¸ ì§€ì›
- ë¡¤ë°± ê°€ëŠ¥í•œ ë°°í¬

### 2. ì„±ëŠ¥ ìµœì í™”
```python
# ë°°ì¹˜ ì²˜ë¦¬
@batch_processor(batch_size=32)
async def process_batch(texts: List[str]):
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    pass

# ëª¨ë¸ ìºì‹±
@lru_cache(maxsize=1)
def load_model():
    return torch.load("model.pt")

# GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
torch.cuda.empty_cache()
```

### 3. ì—ëŸ¬ ì²˜ë¦¬
```python
try:
    result = await model.predict(text)
except torch.cuda.OutOfMemoryError:
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ì¬ì‹œë„
    torch.cuda.empty_cache()
    result = await model.predict(text)
except ModelError as e:
    # í´ë°± ëª¨ë¸ ì‚¬ìš©
    result = await fallback_model.predict(text)
```

### 4. ëª¨ë‹ˆí„°ë§
```python
# ì¶”ë¡  ì‹œê°„ ì¸¡ì •
@measure_inference_time
async def predict(self, text: str):
    # ëª¨ë¸ ì¶”ë¡ 
    pass

# ì •í™•ë„ ì¶”ì 
metrics.record_accuracy(predicted, actual)
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```bash
pytest tests/unit/
```

### ëª¨ë¸ í…ŒìŠ¤íŠ¸
```bash
pytest tests/models/ -v
```

### í†µí•© í…ŒìŠ¤íŠ¸
```bash
pytest tests/integration/
```

### í…ŒìŠ¤íŠ¸ ì‘ì„± ì˜ˆì‹œ
```python
class TestNERModel:
    def test_company_extraction(self):
        # Given
        text = "ì‚¼ì„±ì „ìê°€ ìƒˆë¡œìš´ ë°˜ë„ì²´ ê³µì¥ì„ ê±´ì„¤í•©ë‹ˆë‹¤."
        
        # When
        entities = extractor.extract(text)
        
        # Then
        assert any(e.text == "ì‚¼ì„±ì „ì" and e.type == "COMPANY" for e in entities)
    
    @pytest.mark.parametrize("text,expected", [
        ("ê¸ì •ì ì¸ ì‹¤ì  ë°œí‘œ", "positive"),
        ("ì†ì‹¤ì´ í¬ê²Œ ì¦ê°€í–ˆë‹¤", "negative"),
    ])
    def test_sentiment_analysis(self, text, expected):
        result = analyzer.analyze(text)
        assert result.label == expected
```

## ğŸš€ ë°°í¬

### Docker ë¹Œë“œ
```bash
# CPU ë²„ì „
docker build -t riskradar/ml-service:latest .

# GPU ë²„ì „
docker build -f Dockerfile.gpu -t riskradar/ml-service:latest-gpu .
```

### í™˜ê²½ ë³€ìˆ˜
```env
# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_CONSUMER_GROUP=ml-service

# Model
MODEL_PATH=/app/models
MODEL_VERSION=v1.0.0

# GPU
CUDA_VISIBLE_DEVICES=0

# API
API_PORT=8002
API_WORKERS=4
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### Health Check
```python
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "model_loaded": model_manager.is_loaded(),
        "gpu_available": torch.cuda.is_available(),
        "kafka_connected": check_kafka_connection()
    }
```

### Metrics
- ì¶”ë¡  ì‹œê°„ (P50, P95, P99)
- ì²˜ë¦¬ëŸ‰ (ìš”ì²­/ì´ˆ)
- ëª¨ë¸ ì •í™•ë„
- GPU ì‚¬ìš©ë¥ 
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

## ğŸ”’ ë³´ì•ˆ

### ëª¨ë¸ ë³´ì•ˆ
- ëª¨ë¸ íŒŒì¼ ì•”í˜¸í™”
- ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬
- ëª¨ë¸ ë¬´ê²°ì„± ê²€ì¦

### ë°ì´í„° ë³´ì•ˆ
- PII ë§ˆìŠ¤í‚¹
- ë¡œê·¸ í•„í„°ë§
- ë¯¼ê° ì •ë³´ ì œê±°

## ğŸ¤ í˜‘ì—…

### Input/Output
- **Input**: Kafka topic `raw-news`
- **Output**: Kafka topic `enriched-news`
- **Schema**: [EnrichedNewsModel](schemas.py)

### API ì—”ë“œí¬ì¸íŠ¸
- `POST /process`: ë‹¨ì¼ í…ìŠ¤íŠ¸ ì²˜ë¦¬
- `POST /batch`: ë°°ì¹˜ ì²˜ë¦¬
- `GET /model/info`: ëª¨ë¸ ì •ë³´

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 0. ë¹Œë“œ íƒ€ì„ì•„ì›ƒ
```bash
# ê²½ëŸ‰ ë²„ì „ìœ¼ë¡œ ë¹Œë“œ
docker build -t ml-service .

# ML ì˜ì¡´ì„±ì€ ëŸ°íƒ€ì„ì— ì„¤ì¹˜
docker exec ml-service pip install -r requirements-ml.txt
```

#### 1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
BATCH_SIZE = 16  # 32ì—ì„œ ê°ì†Œ

# ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…
model.gradient_checkpointing_enable()
```

#### 2. ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
```bash
# ëª¨ë¸ íŒŒì¼ í™•ì¸
ls -la /app/models/

# ê¶Œí•œ í™•ì¸
chmod -R 755 /app/models/
```

#### 3. ëŠë¦° ì¶”ë¡  ì†ë„
- ë°°ì¹˜ ì²˜ë¦¬ í™œìš©
- ëª¨ë¸ ê²½ëŸ‰í™” (ì–‘ìí™”)
- TorchScript ë³€í™˜

## ğŸ“š ì°¸ê³  ìë£Œ

- [KoBERT Documentation](https://github.com/SKTBrain/KoBERT)
- [KoNLPy Documentation](https://konlpy.org/)
- [PyTorch Documentation](https://pytorch.org/docs/)

## ğŸ“ ë¬¸ì„œ ê´€ë¦¬ ê°€ì´ë“œë¼ì¸

### ë¬¸ì„œ ì—­í•  êµ¬ë¶„
- **CLAUDE.md**: ê°œë°œ ê°€ì´ë“œë¼ì¸ë§Œ ì‘ì„± (í™˜ê²½ ì„¤ì •, ì½”ë”© ê·œì¹™, í…ŒìŠ¤íŠ¸ ë°©ë²•)
- **README.md**: í”„ë¡œì íŠ¸ ê´€ë ¨ ë‚´ìš© (ê°œìš”, í˜„ì¬ ìƒíƒœ, ì•„í‚¤í…ì²˜, ì‚¬ìš©ë²•)
- **CHANGELOG.md**: ê°œë°œ ìˆ˜í–‰ ë‚´ìš© ê¸°ë¡ (Sprintë³„ ì„±ê³¼, ë³€ê²½ì‚¬í•­ ìƒì„¸)

## ğŸ“ í”„ë¡œì íŠ¸ ë¬¸ì„œ

### í•µì‹¬ ë¬¸ì„œ
- [ML/NLP Squad TRD](../../docs/trd/phase1/TRD_ML_NLP_Squad_P1.md) - ê¸°ìˆ  ëª…ì„¸
- [API í‘œì¤€](../../docs/trd/common/API_Standards.md) - API ì„¤ê³„
- [ë°ì´í„° ëª¨ë¸](../../docs/trd/common/Data_Models.md) - ê³µí†µ êµ¬ì¡°

### ì—°ê´€ ì„œë¹„ìŠ¤
- [Data Service](../data-service/CLAUDE.md) - Kafka ë©”ì‹œì§€ ì†¡ì‹ 
- [Graph Service](../graph-service/CLAUDE.md) - ì²˜ë¦¬ ê²°ê³¼ ì „ë‹¬
- [í†µí•© ê°€ì´ë“œ](../../integration/README.md) - ì‹œìŠ¤í…œ í†µí•©