# ML Service Development Guidelines
# ML/NLP ì„œë¹„ìŠ¤ ê°œë°œ ê°€ì´ë“œë¼ì¸

## ğŸ“‹ ì„œë¹„ìŠ¤ ê°œìš”

ML ServiceëŠ” RiskRadarì˜ ìì—°ì–´ ì²˜ë¦¬ ë° ë¨¸ì‹ ëŸ¬ë‹ ì¶”ë¡ ì„ ë‹´ë‹¹í•˜ëŠ” ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. í•œêµ­ì–´ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•˜ê³ , ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ë©°, ë¦¬ìŠ¤í¬ ê´€ë ¨ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ğŸ¯ í˜„ì¬ ìƒíƒœ (Sprint 1 Week 3 ì™„ë£Œ)

- âœ… **FastAPI ê¸°ë°˜ ML ì„œë¹„ìŠ¤ êµ¬ì¶•** - ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì²˜ë¦¬
- âœ… **ë‹¤ì¤‘ NER ëª¨ë¸ ì§€ì›** - Mock, KLUE-BERT, KoELECTRA ë“±
- âœ… **Kafka í†µí•©** - ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- âœ… **í¬ê´„ì ì¸ í‰ê°€ ì‹œìŠ¤í…œ** - F1 Score ê¸°ë°˜ ëª¨ë¸ ì„±ëŠ¥ ì¸¡ì •
- âœ… **ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”** - ëŒ€ìš©ëŸ‰ ë‰´ìŠ¤ ë°ì´í„° íš¨ìœ¨ì  ì²˜ë¦¬
- âœ… **ìºì‹± ì‹œìŠ¤í…œ** - Redis ê¸°ë°˜ ì„±ëŠ¥ ìµœì í™”
- âœ… **í…ŒìŠ¤íŠ¸ ìë™í™”** - ë‹¨ìœ„/í†µí•© í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ ê²€ì¦
- âœ… **í–¥ìƒëœ ê°ì • ë¶„ì„** - í•œêµ­ì–´ ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸ íŠ¹í™” ë¶„ì„ê¸°
- âœ… **ê³ ë„í™”ëœ ë¦¬ìŠ¤í¬ ë¶„ì„** - ë‹¤ì¤‘ íŒ©í„° ë¦¬ìŠ¤í¬ í‰ê°€ ëª¨ë¸
- âœ… **ê°•í™”ëœ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸** - ì—”í‹°í‹° ì»¨í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„

### ğŸ“¡ ì ‘ì† ì •ë³´
- **API Endpoint**: http://localhost:8002
- **Health Check**: http://localhost:8002/health
- **API Docs**: http://localhost:8002/docs

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ml-service/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/             # ML ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ ner/           # ê°œì²´ëª… ì¸ì‹ ëª¨ë¸
â”‚   â”‚   â”‚   â”œâ”€â”€ enhanced_rule_ner.py    # í–¥ìƒëœ ê·œì¹™ ê¸°ë°˜ NER
â”‚   â”‚   â”‚   â”œâ”€â”€ koelectra_ner.py        # KoELECTRA NER ëª¨ë¸
â”‚   â”‚   â”‚   â”œâ”€â”€ postprocessor.py        # í›„ì²˜ë¦¬ ëª¨ë“ˆ
â”‚   â”‚   â”‚   â”œâ”€â”€ entity_linker.py        # ì—”í‹°í‹° ì—°ê²°
â”‚   â”‚   â”‚   â”œâ”€â”€ company_matcher.py      # íšŒì‚¬ëª… ë§¤ì¹­
â”‚   â”‚   â”‚   â”œâ”€â”€ cache_manager.py        # ìºì‹œ ê´€ë¦¬
â”‚   â”‚   â”‚   â””â”€â”€ knowledge_base.py       # ì§€ì‹ ë² ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ sentiment/     # ê°ì • ë¶„ì„ (Week 3 ê°•í™”)
â”‚   â”‚   â”‚   â”œâ”€â”€ enhanced_sentiment.py   # ìƒˆë¡œ ì¶”ê°€: í–¥ìƒëœ ê°ì • ë¶„ì„ê¸°
â”‚   â”‚   â”‚   â””â”€â”€ mock_sentiment.py       # Mock ê°ì • ë¶„ì„
â”‚   â”‚   â””â”€â”€ risk/          # ë¦¬ìŠ¤í¬ ë¶„ë¥˜ (Week 3 ê°•í™”)
â”‚   â”‚       â”œâ”€â”€ risk_analyzer.py        # ìƒˆë¡œ ì¶”ê°€: ì¢…í•© ë¦¬ìŠ¤í¬ ë¶„ì„ê¸°
â”‚   â”‚       â””â”€â”€ risk_classifier.py      # ê¸°ì¡´ ë¦¬ìŠ¤í¬ ë¶„ë¥˜ê¸°
â”‚   â”œâ”€â”€ processors/        # NLP ì „ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ tokenizer.py   # í•œêµ­ì–´ í† í¬ë‚˜ì´ì €
â”‚   â”‚   â”œâ”€â”€ normalizer.py  # í…ìŠ¤íŠ¸ ì •ê·œí™”
â”‚   â”‚   â””â”€â”€ pipeline.py    # ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ kafka/             # Kafka ì—°ë™
â”‚   â”‚   â”œâ”€â”€ consumer.py    # ì‹¤ì‹œê°„ ë©”ì‹œì§€ ì†Œë¹„
â”‚   â”‚   â”œâ”€â”€ producer.py    # ì²˜ë¦¬ ê²°ê³¼ ë°œí–‰
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/              # REST API
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ config.py         # ì„¤ì • ê´€ë¦¬
â”‚   â””â”€â”€ main.py           # ì„œë¹„ìŠ¤ ì§„ì…ì 
â”œâ”€â”€ tests/                # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ unit/             # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ integration/      # í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_data/        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”œâ”€â”€ mock-data/            # ê°œë°œìš© Mock ë°ì´í„°
â”œâ”€â”€ requirements.txt      # Python ì˜ì¡´ì„±
â”œâ”€â”€ .env                  # í™˜ê²½ ë³€ìˆ˜
â”œâ”€â”€ Dockerfile           # ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€
â”œâ”€â”€ README.md            # í”„ë¡œì íŠ¸ ì •ë³´
â”œâ”€â”€ CLAUDE.md            # í˜„ì¬ íŒŒì¼
â””â”€â”€ CHANGELOG.md         # ë³€ê²½ ì´ë ¥
```

## ğŸ’» ê°œë°œ í™˜ê²½ ì„¤ì •

### Prerequisites
```bash
Python 3.11+
CUDA 11.8+ (GPU ì‚¬ìš© ì‹œ)
Poetry ë˜ëŠ” pip
Docker
```

### ì„¤ì¹˜
```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate

# ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜ (ë¹ ë¥¸ ì‹œì‘)
pip install -r requirements.txt

# ML í”„ë ˆì„ì›Œí¬ ì„¤ì¹˜ (ì „ì²´ ê¸°ëŠ¥)
pip install -r requirements-ml.txt

# ë˜ëŠ” GPU ë²„ì „ ì„¤ì¹˜
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install transformers

# í•œêµ­ì–´ NLP ë„êµ¬ ì„¤ì¹˜
python -m konlpy.downloader all
```

### Docker ë¹Œë“œ
```bash
# ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© (ê²½ëŸ‰)
docker build -t ml-service .

# í”„ë¡œë•ì…˜ìš© (ML í¬í•¨)
docker build -f Dockerfile.prod -t ml-service:prod .
```

### ë¡œì»¬ ì‹¤í–‰
```bash
# ì„œë¹„ìŠ¤ ì‹¤í–‰
python -m src.main

# ë˜ëŠ” ê°œë°œ ëª¨ë“œ
uvicorn src.main:app --reload --port 8002
```

## ğŸ”§ ì£¼ìš” ì»´í¬ë„ŒíŠ¸

### 1. NLP Pipeline
```python
class NLPPipeline:
    """í•œêµ­ì–´ NLP ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.tokenizer = SimpleTokenizer()  # Java ë¯¸ì„¤ì¹˜ í™˜ê²½
        self.ner_model = KoElectraNaverNERModel()  # ìµœì‹  ëª¨ë¸
        self.sentiment_analyzer = SentimentAnalyzer()
        self.keyword_extractor = KeywordExtractor()
        
    async def process(self, text: str) -> ProcessedResult:
        """í…ìŠ¤íŠ¸ ì²˜ë¦¬"""
        # 1. ì „ì²˜ë¦¬
        normalized = normalize_text(text)
        
        # 2. í† í°í™”
        tokens = self.tokenizer.tokenize(normalized)
        
        # 3. NER (ìºì‹± ì§€ì›)
        entities = self.ner_model.extract_entities(text)
        
        # 4. ê°ì • ë¶„ì„
        sentiment = self.sentiment_analyzer.analyze(text)
        
        # 5. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.keyword_extractor.extract(tokens)
        
        # 6. ë¦¬ìŠ¤í¬ ì ìˆ˜
        risk_score = calculate_risk_score(sentiment, keywords)
        
        return ProcessedResult(
            entities=entities,
            sentiment=sentiment,
            keywords=keywords,
            risk_score=risk_score
        )
```

### 2. Enhanced Sentiment Analysis (Week 3 ì¶”ê°€)
```python
class EnhancedSentimentAnalyzer:
    """í–¥ìƒëœ í•œêµ­ì–´ ë¹„ì¦ˆë‹ˆìŠ¤ ë„ë©”ì¸ ê°ì • ë¶„ì„ê¸°"""
    
    def __init__(self):
        # ê¸ì •ì  ì§€í‘œë“¤
        self.positive_indicators = {
            'growth': ['ì¦ê°€', 'ìƒìŠ¹', 'ì„±ì¥', 'í™•ëŒ€', 'ê¸‰ì¦', 'í˜¸ì¡°'],
            'success': ['ì„±ê³µ', 'ë‹¬ì„±', 'ê¸°ë¡', 'ì„±ê³¼', 'ìˆ˜ìµ', 'ì´ìµ'],
            'positive_business': ['íˆ¬ì', 'í™•ì¥', 'ì§„ì¶œ', 'ì¶œì‹œ', 'ëŸ°ì¹­'],
        }
        
        # ë¶€ì •ì  ì§€í‘œë“¤  
        self.negative_indicators = {
            'decline': ['ê°ì†Œ', 'í•˜ë½', 'ê¸‰ë½', 'í­ë½', 'í•˜í–¥'],
            'problems': ['ë¬¸ì œ', 'ì´ìŠˆ', 'ìš°ë ¤', 'ìœ„í—˜', 'ë¦¬ìŠ¤í¬'],
            'financial_stress': ['ì—°ì²´', 'ë¶€ì‹¤', 'íŒŒì‚°', 'íšŒìƒ', 'ë¶€ì±„'],
        }
        
        # ê°•í™”/ì•½í™” ìˆ˜ì‹ì–´
        self.intensifiers = {
            'strong_positive': ['ëŒ€í­', 'í¬ê²Œ', 'ê¸‰ê²©íˆ', 'í˜„ì €íˆ'],
            'strong_negative': ['ëŒ€í­', 'í¬ê²Œ', 'ê¸‰ê²©íˆ', 'ì‹¬ê°í•˜ê²Œ'],
            'mild': ['ì†Œí­', 'ì•½ê°„', 'ë‹¤ì†Œ', 'ì¼ë¶€'],
        }
    
    def analyze_sentiment(self, text: str, entities: Optional[List] = None) -> Sentiment:
        """
        í–¥ìƒëœ ê°ì • ë¶„ì„
        - ë‹¤ì¤‘ ì¹´í…Œê³ ë¦¬ ì§€í‘œ ë¶„ì„
        - ê°•í™”/ì•½í™” ìˆ˜ì‹ì–´ ì²˜ë¦¬
        - ë¶€ì • í‘œí˜„ í•¸ë“¤ë§
        - ì—”í‹°í‹° ì»¨í…ìŠ¤íŠ¸ í†µí•©
        """
        sentiment_scores = self._calculate_sentiment_scores(text)
        
        # ì—”í‹°í‹° ê¸°ë°˜ ì¡°ì •
        if entities:
            sentiment_scores = self._adjust_with_entities(sentiment_scores, entities, text)
        
        return self._determine_final_sentiment(sentiment_scores)
```

### 3. Comprehensive Risk Analysis (Week 3 ì¶”ê°€)
```python
class EnhancedRiskAnalyzer:
    """ë‹¤ì¤‘ íŒ©í„° ë¦¬ìŠ¤í¬ ë¶„ì„ê¸°"""
    
    def __init__(self):
        # ê¸ˆìœµ ë¦¬ìŠ¤í¬ ìš”ì†Œ
        self.financial_risks = {
            'debt_default': ['ì—°ì²´', 'ë¶€ì‹¤', 'ì±„ë¬´ë¶ˆì´í–‰', 'ë””í´íŠ¸', 'íŒŒì‚°'],
            'liquidity_crisis': ['ìœ ë™ì„±', 'ìê¸ˆë¶€ì¡±', 'í˜„ê¸ˆíë¦„', 'ê¸´ê¸‰ìê¸ˆ'],
            'credit_rating': ['ì‹ ìš©ë“±ê¸‰', 'ë“±ê¸‰í•˜í–¥', 'ë“±ê¸‰ìƒí–¥', 'ì‹ ìš©í‰ê°€'],
        }
        
        # ìš´ì˜ ë¦¬ìŠ¤í¬ ìš”ì†Œ
        self.operational_risks = {
            'supply_chain': ['ê³µê¸‰ë§', 'ì›ì¬ë£Œ', 'ë¶€í’ˆë¶€ì¡±', 'ë‚©ê¸°ì§€ì—°'],
            'production_issues': ['ìƒì‚°ì¤‘ë‹¨', 'ê°€ë™ì¤‘ë‹¨', 'ê³µì¥íì‡„', 'í’ˆì§ˆë¬¸ì œ'],
            'labor_issues': ['íŒŒì—…', 'ë…¸ì‚¬ê°ˆë“±', 'ì„ê¸ˆí˜‘ìƒ', 'ì •ë¦¬í•´ê³ '],
        }
        
        # ESG ë¦¬ìŠ¤í¬
        self.esg_risks = {
            'environmental': ['í™˜ê²½ì˜¤ì—¼', 'íƒ„ì†Œë°°ì¶œ', 'íìˆ˜', 'í™˜ê²½ê·œì œ'],
            'social': ['ì‚¬íšŒì ì±…ì„', 'ì¸ê¶Œ', 'ë‹¤ì–‘ì„±', 'ì§€ì—­ì‚¬íšŒ'],
            'governance': ['ì§€ë°°êµ¬ì¡°', 'íˆ¬ëª…ì„±', 'ì´ì‚¬íšŒ', 'ë‚´ë¶€ê±°ë˜'],
        }
    
    def analyze_risk(self, text: str, entities: Optional[List] = None, 
                    sentiment: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ì¢…í•©ì ì¸ ë¦¬ìŠ¤í¬ ë¶„ì„
        - ë‹¤ì¤‘ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤í¬ í‰ê°€ (ê¸ˆìœµ, ìš´ì˜, ë²•ì , ì‹œì¥, ESG)
        - ì´ë²¤íŠ¸ ì‹¬ê°ë„ ê²€ì¶œ
        - ì—”í‹°í‹° ë° ê°ì • í†µí•© ë¶„ì„
        - ë¦¬ìŠ¤í¬ íŠ¸ë Œë“œ ë° ì˜ˆì¸¡
        """
        # 1. ë¦¬ìŠ¤í¬ ì´ë²¤íŠ¸ ê°ì§€
        risk_events = self._detect_risk_events(text)
        
        # 2. ì¹´í…Œê³ ë¦¬ë³„ ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°
        category_scores = self._calculate_category_scores(text, risk_events)
        
        # 3. ì—”í‹°í‹° ê¸°ë°˜ ì¡°ì •
        if entities:
            category_scores = self._adjust_with_entities(category_scores, entities, text)
        
        # 4. ê°ì • ê¸°ë°˜ ì¡°ì •
        if sentiment:
            category_scores = self._adjust_with_sentiment(category_scores, sentiment)
        
        # 5. ì¢…í•© ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°
        overall_risk_score = self._calculate_overall_risk(category_scores)
        
        return {
            'overall_risk_score': overall_risk_score,
            'risk_level': self._determine_risk_level(overall_risk_score),
            'category_scores': category_scores,
            'detected_events': risk_events,
            'risk_summary': self._generate_risk_summary(risk_events, category_scores)
        }
```

### 4. Entity Extraction
```python
class EntityExtractor:
    """ê°œì²´ëª… ì¸ì‹"""
    
    def __init__(self, model_path: str):
        self.model = KoBERTForNER.from_pretrained(model_path)
        self.label_map = {
            0: "O",
            1: "B-COMPANY",
            2: "I-COMPANY",
            3: "B-PERSON",
            4: "I-PERSON",
            # ...
        }
    
    async def extract(self, tokens: List[str]) -> List[Entity]:
        """ì—”í‹°í‹° ì¶”ì¶œ"""
        # ì¸ì½”ë”©
        inputs = self.tokenizer.encode_plus(tokens, return_tensors="pt")
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = self.model(**inputs)
            predictions = torch.argmax(outputs.logits, dim=-1)
        
        # ë””ì½”ë”©
        entities = self.decode_predictions(tokens, predictions)
        return entities
```

### 3. Kafka Integration
```python
class MLConsumer:
    """Kafka ì»¨ìŠˆë¨¸"""
    
    def __init__(self):
        self.consumer = KafkaConsumer(
            'raw-news',
            bootstrap_servers=KAFKA_SERVERS,
            value_deserializer=lambda m: json.loads(m.decode('utf-8'))
        )
        self.producer = MLProducer()
        self.pipeline = NLPPipeline()
    
    async def process_messages(self):
        """ë©”ì‹œì§€ ì²˜ë¦¬ ë£¨í”„"""
        for message in self.consumer:
            try:
                # ì›ë³¸ ë‰´ìŠ¤
                news = message.value
                
                # NLP ì²˜ë¦¬
                result = await self.pipeline.process(news['content'])
                
                # ê²°ê³¼ ë°œí–‰
                enriched = {
                    "original": news,
                    "nlp": result.dict(),
                    "processed_at": datetime.now().isoformat()
                }
                
                await self.producer.send_enriched(enriched)
                
            except Exception as e:
                logger.error(f"Processing failed: {e}")
                # DLQë¡œ ì „ì†¡
```

## ğŸ“ ì½”ë”© ê·œì¹™

### 1. ëª¨ë¸ ê´€ë¦¬
- ëª¨ë¸ ë²„ì „ ê´€ë¦¬ (DVC ì‚¬ìš©)
- ëª¨ë¸ ë©”íƒ€ë°ì´í„° ê¸°ë¡
- A/B í…ŒìŠ¤íŠ¸ ì§€ì›
- ë¡¤ë°± ê°€ëŠ¥í•œ ë°°í¬

### 2. ì„±ëŠ¥ ìµœì í™”
```python
# ë°°ì¹˜ ì²˜ë¦¬
@batch_processor(batch_size=32)
async def process_batch(texts: List[str]):
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    pass

# ëª¨ë¸ ìºì‹±
@lru_cache(maxsize=1)
def load_model():
    return torch.load("model.pt")

# GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
torch.cuda.empty_cache()
```

### 3. ì—ëŸ¬ ì²˜ë¦¬
```python
try:
    result = await model.predict(text)
except torch.cuda.OutOfMemoryError:
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ì¬ì‹œë„
    torch.cuda.empty_cache()
    result = await model.predict(text)
except ModelError as e:
    # í´ë°± ëª¨ë¸ ì‚¬ìš©
    result = await fallback_model.predict(text)
```

### 4. ëª¨ë‹ˆí„°ë§
```python
# ì¶”ë¡  ì‹œê°„ ì¸¡ì •
@measure_inference_time
async def predict(self, text: str):
    # ëª¨ë¸ ì¶”ë¡ 
    pass

# ì •í™•ë„ ì¶”ì 
metrics.record_accuracy(predicted, actual)
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```bash
pytest tests/unit/
```

### ëª¨ë¸ í…ŒìŠ¤íŠ¸
```bash
pytest tests/models/ -v
```

### í†µí•© í…ŒìŠ¤íŠ¸
```bash
pytest tests/integration/
```

### í…ŒìŠ¤íŠ¸ ì‘ì„± ì˜ˆì‹œ
```python
class TestNERModel:
    def test_company_extraction(self):
        # Given
        text = "ì‚¼ì„±ì „ìê°€ ìƒˆë¡œìš´ ë°˜ë„ì²´ ê³µì¥ì„ ê±´ì„¤í•©ë‹ˆë‹¤."
        
        # When
        entities = extractor.extract(text)
        
        # Then
        assert any(e.text == "ì‚¼ì„±ì „ì" and e.type == "COMPANY" for e in entities)
    
    @pytest.mark.parametrize("text,expected", [
        ("ê¸ì •ì ì¸ ì‹¤ì  ë°œí‘œ", "positive"),
        ("ì†ì‹¤ì´ í¬ê²Œ ì¦ê°€í–ˆë‹¤", "negative"),
    ])
    def test_sentiment_analysis(self, text, expected):
        result = analyzer.analyze(text)
        assert result.label == expected
```

## ğŸš€ ë°°í¬

### Docker ë¹Œë“œ
```bash
# CPU ë²„ì „
docker build -t riskradar/ml-service:latest .

# GPU ë²„ì „
docker build -f Dockerfile.gpu -t riskradar/ml-service:latest-gpu .
```

### í™˜ê²½ ë³€ìˆ˜
```env
# Development mode
USE_MOCK_KAFKA=false
USE_SIMPLE_TOKENIZER=true

# API settings
API_HOST=0.0.0.0
API_PORT=8082

# Kafka settings (local development)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_CONSUMER_GROUP=ml-service
KAFKA_INPUT_TOPIC=raw-news
KAFKA_OUTPUT_TOPIC=enriched-news

# Model settings
MODEL_PATH=/app/models
MODEL_VERSION=v1.0.0
TOKENIZER_BACKEND=komoran

# Processing settings
BATCH_SIZE=32
MAX_PROCESSING_TIME_MS=100
ENABLE_GPU=false

# Logging
LOG_LEVEL=INFO
```

### ì‹¤ì œ Kafka í†µí•© (Production Mode)
```bash
# Kafka ì„œë¹„ìŠ¤ ì—°ê²° í™•ì¸
docker exec riskradar-kafka kafka-topics --bootstrap-server localhost:9092 --list

# ë©”ì‹œì§€ ìƒì‚° í…ŒìŠ¤íŠ¸
echo '{"id": "test-001", "title": "í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤", "content": "ì‚¼ì„±ì „ìê°€ ìƒˆë¡œìš´ íˆ¬ìë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤."}' | \
  docker exec -i riskradar-kafka kafka-console-producer \
  --bootstrap-server localhost:9092 --topic raw-news

# ì²˜ë¦¬ëœ ë©”ì‹œì§€ í™•ì¸
docker exec riskradar-kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 --topic enriched-news \
  --from-beginning --max-messages 1 | jq '.nlp.entities'
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### Health Check
```python
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "model_loaded": model_manager.is_loaded(),
        "gpu_available": torch.cuda.is_available(),
        "kafka_connected": check_kafka_connection()
    }
```

### Metrics
- ì¶”ë¡  ì‹œê°„ (P50, P95, P99)
- ì²˜ë¦¬ëŸ‰ (ìš”ì²­/ì´ˆ)
- ëª¨ë¸ ì •í™•ë„
- GPU ì‚¬ìš©ë¥ 
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

## ğŸ”’ ë³´ì•ˆ

### ëª¨ë¸ ë³´ì•ˆ
- ëª¨ë¸ íŒŒì¼ ì•”í˜¸í™”
- ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬
- ëª¨ë¸ ë¬´ê²°ì„± ê²€ì¦

### ë°ì´í„° ë³´ì•ˆ
- PII ë§ˆìŠ¤í‚¹
- ë¡œê·¸ í•„í„°ë§
- ë¯¼ê° ì •ë³´ ì œê±°

## ğŸ¤ í˜‘ì—…

### Input/Output
- **Input**: Kafka topic `raw-news`
- **Output**: Kafka topic `enriched-news`
- **Schema**: [EnrichedNewsModel](schemas.py)

### API ì—”ë“œí¬ì¸íŠ¸
- `POST /process`: ë‹¨ì¼ í…ìŠ¤íŠ¸ ì²˜ë¦¬
- `POST /batch`: ë°°ì¹˜ ì²˜ë¦¬
- `GET /model/info`: ëª¨ë¸ ì •ë³´

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 0. ë¹Œë“œ íƒ€ì„ì•„ì›ƒ
```bash
# ê²½ëŸ‰ ë²„ì „ìœ¼ë¡œ ë¹Œë“œ
docker build -t ml-service .

# ML ì˜ì¡´ì„±ì€ ëŸ°íƒ€ì„ì— ì„¤ì¹˜
docker exec ml-service pip install -r requirements-ml.txt
```

#### 1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
BATCH_SIZE = 16  # 32ì—ì„œ ê°ì†Œ

# ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…
model.gradient_checkpointing_enable()
```

#### 2. ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
```bash
# ëª¨ë¸ íŒŒì¼ í™•ì¸
ls -la /app/models/

# ê¶Œí•œ í™•ì¸
chmod -R 755 /app/models/
```

#### 3. ëŠë¦° ì¶”ë¡  ì†ë„
- ë°°ì¹˜ ì²˜ë¦¬ í™œìš©
- ëª¨ë¸ ê²½ëŸ‰í™” (ì–‘ìí™”)
- TorchScript ë³€í™˜

## ğŸ“š ì°¸ê³  ìë£Œ

- [KoBERT Documentation](https://github.com/SKTBrain/KoBERT)
- [KoNLPy Documentation](https://konlpy.org/)
- [PyTorch Documentation](https://pytorch.org/docs/)

## ğŸ“ ë¬¸ì„œ ê´€ë¦¬ ê°€ì´ë“œë¼ì¸

### ë¬¸ì„œ ì—­í•  êµ¬ë¶„
- **CLAUDE.md**: ê°œë°œ ê°€ì´ë“œë¼ì¸ë§Œ ì‘ì„± (í™˜ê²½ ì„¤ì •, ì½”ë”© ê·œì¹™, í…ŒìŠ¤íŠ¸ ë°©ë²•)
- **README.md**: í”„ë¡œì íŠ¸ ê´€ë ¨ ë‚´ìš© (ê°œìš”, í˜„ì¬ ìƒíƒœ, ì•„í‚¤í…ì²˜, ì‚¬ìš©ë²•)
- **CHANGELOG.md**: ê°œë°œ ìˆ˜í–‰ ë‚´ìš© ê¸°ë¡ (Sprintë³„ ì„±ê³¼, ë³€ê²½ì‚¬í•­ ìƒì„¸)

## ğŸ“ í”„ë¡œì íŠ¸ ë¬¸ì„œ

### í•µì‹¬ ë¬¸ì„œ
- [ML/NLP Squad TRD](../../docs/trd/phase1/TRD_ML_NLP_Squad_P1.md) - ê¸°ìˆ  ëª…ì„¸
- [API í‘œì¤€](../../docs/trd/common/API_Standards.md) - API ì„¤ê³„
- [ë°ì´í„° ëª¨ë¸](../../docs/trd/common/Data_Models.md) - ê³µí†µ êµ¬ì¡°

### ì—°ê´€ ì„œë¹„ìŠ¤
- [Data Service](../data-service/CLAUDE.md) - Kafka ë©”ì‹œì§€ ì†¡ì‹ 
- [Graph Service](../graph-service/CLAUDE.md) - ì²˜ë¦¬ ê²°ê³¼ ì „ë‹¬
- [í†µí•© ê°€ì´ë“œ](../../integration/README.md) - ì‹œìŠ¤í…œ í†µí•©