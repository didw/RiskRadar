"""
ë¶€í•˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Sprint 1 ìš”êµ¬ì‚¬í•­: ë™ì‹œ 100 ì¿¼ë¦¬ ì²˜ë¦¬, Write TPS > 100 ë‹¬ì„± ê²€ì¦
"""
import asyncio
import aiohttp
import time
import json
import statistics
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
import logging
import sys
import os
import concurrent.futures
from threading import Thread

# ìƒìœ„ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.neo4j.driver import driver

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class LoadTestResult:
    """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    test_name: str
    concurrent_users: int
    total_requests: int
    duration_seconds: float
    requests_per_second: float
    successful_requests: int
    failed_requests: int
    success_rate: float
    avg_response_time_ms: float
    p95_response_time_ms: float
    p99_response_time_ms: float
    max_response_time_ms: float
    min_response_time_ms: float
    errors: List[str]
    goal_achieved: bool


class GraphServiceLoadTest:
    """Graph Service ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self, base_url: str = "http://localhost:8003"):
        self.base_url = base_url
        self.test_company_ids = []
        self.results: List[LoadTestResult] = []
        
    async def setup_test_data(self):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì •"""
        try:
            # ê¸°ì¡´ íšŒì‚¬ ID ì¡°íšŒ
            query = "MATCH (c:Company) RETURN c.id as id LIMIT 20"
            results = driver.execute_read(query)
            self.test_company_ids = [row["id"] for row in results if row["id"]]
            
            # ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒì„±
            if len(self.test_company_ids) < 10:
                await self._create_load_test_data()
                results = driver.execute_read(query)
                self.test_company_ids = [row["id"] for row in results if row["id"]]
            
            logger.info(f"Using {len(self.test_company_ids)} companies for load testing")
            
        except Exception as e:
            logger.error(f"Error setting up test data: {e}")
            # í´ë°±: ë”ë¯¸ ID ì‚¬ìš©
            self.test_company_ids = [f"load-test-company-{i}" for i in range(20)]
    
    async def _create_load_test_data(self):
        """ë¶€í•˜ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±"""
        logger.info("Creating load test data...")
        
        # 100ê°œ ê¸°ì—… ìƒì„±
        batch_size = 10
        for batch in range(0, 100, batch_size):
            companies = []
            for i in range(batch, min(batch + batch_size, 100)):
                companies.append({
                    "id": f"load-test-company-{i}",
                    "name": f"Load Test Company {i}",
                    "sector": ["Technology", "Finance", "Healthcare", "Energy", "Retail"][i % 5],
                    "risk_score": 3.0 + (i % 8),  # 3.0 ~ 10.0
                    "market_cap": 100000000 + (i * 50000000),  # ë‹¤ì–‘í•œ ì‹œê°€ì´ì•¡
                    "created_at": int(time.time())
                })
            
            # ë°°ì¹˜ ìƒì„±
            query = """
            UNWIND $companies as company
            CREATE (c:Company {
                id: company.id,
                name: company.name,
                sector: company.sector,
                risk_score: company.risk_score,
                market_cap: company.market_cap,
                created_at: company.created_at
            })
            """
            
            try:
                driver.execute_write(query, companies=companies)
            except Exception as e:
                logger.debug(f"Batch creation failed (may already exist): {e}")
        
        # ê´€ê³„ ìƒì„± (ì—°ê²°ëœ ë„¤íŠ¸ì›Œí¬ êµ¬ì„±)
        logger.info("Creating relationships for load test...")
        
        for i in range(0, 90, 10):
            relationships = []
            for j in range(i, i + 10):
                if j + 1 < 100:
                    relationships.append({
                        "from_id": f"load-test-company-{j}",
                        "to_id": f"load-test-company-{j + 1}",
                        "strength": 0.5 + (j % 5) * 0.1
                    })
            
            rel_query = """
            UNWIND $rels as rel
            MATCH (c1:Company {id: rel.from_id})
            MATCH (c2:Company {id: rel.to_id})
            CREATE (c1)-[:CONNECTED_TO {strength: rel.strength, created_at: timestamp()}]->(c2)
            """
            
            try:
                driver.execute_write(rel_query, rels=relationships)
            except Exception as e:
                logger.debug(f"Relationship creation failed: {e}")
    
    async def _make_http_request(self, session: aiohttp.ClientSession, 
                                url: str, method: str = "GET", 
                                json_data: Dict = None) -> Dict[str, Any]:
        """HTTP ìš”ì²­ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            if method == "GET":
                async with session.get(url) as response:
                    response_time = (time.time() - start_time) * 1000
                    result = await response.json()
                    return {
                        "success": response.status == 200,
                        "response_time_ms": response_time,
                        "status": response.status,
                        "data": result,
                        "error": None
                    }
            elif method == "POST":
                async with session.post(url, json=json_data) as response:
                    response_time = (time.time() - start_time) * 1000
                    result = await response.json()
                    return {
                        "success": response.status == 200,
                        "response_time_ms": response_time,
                        "status": response.status,
                        "data": result,
                        "error": None
                    }
                    
        except Exception as e:
            response_time = (time.time() - start_time) * 1000
            return {
                "success": False,
                "response_time_ms": response_time,
                "status": 0,
                "data": None,
                "error": str(e)
            }
    
    async def concurrent_read_test(self, concurrent_users: int = 100, 
                                 duration_seconds: int = 60) -> LoadTestResult:
        """ë™ì‹œ ì½ê¸° ìš”ì²­ í…ŒìŠ¤íŠ¸"""
        logger.info(f"Running concurrent read test: {concurrent_users} users for {duration_seconds}s")
        
        results = []
        errors = []
        start_time = time.time()
        end_time = start_time + duration_seconds
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            
            # ë™ì‹œ ì‚¬ìš©ì ì‹œë®¬ë ˆì´ì…˜
            for user_id in range(concurrent_users):
                task = asyncio.create_task(
                    self._simulate_user_read_activity(session, user_id, end_time, results, errors)
                )
                tasks.append(task)
            
            # ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
            await asyncio.gather(*tasks)
        
        actual_duration = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]
        
        if successful_requests:
            response_times = [r["response_time_ms"] for r in successful_requests]
            avg_response_time = statistics.mean(response_times)
            p95_response_time = sorted(response_times)[int(len(response_times) * 0.95)]
            p99_response_time = sorted(response_times)[int(len(response_times) * 0.99)]
            max_response_time = max(response_times)
            min_response_time = min(response_times)
        else:
            avg_response_time = p95_response_time = p99_response_time = 0
            max_response_time = min_response_time = 0
        
        rps = len(results) / actual_duration
        success_rate = len(successful_requests) / len(results) * 100 if results else 0
        
        return LoadTestResult(
            test_name="Concurrent Read Test",
            concurrent_users=concurrent_users,
            total_requests=len(results),
            duration_seconds=actual_duration,
            requests_per_second=rps,
            successful_requests=len(successful_requests),
            failed_requests=len(failed_requests),
            success_rate=success_rate,
            avg_response_time_ms=avg_response_time,
            p95_response_time_ms=p95_response_time,
            p99_response_time_ms=p99_response_time,
            max_response_time_ms=max_response_time,
            min_response_time_ms=min_response_time,
            errors=errors[:10],  # ìµœëŒ€ 10ê°œ ì—ëŸ¬ë§Œ ê¸°ë¡
            goal_achieved=rps >= 50 and success_rate >= 95  # ëª©í‘œ: 50 RPS, 95% ì„±ê³µë¥ 
        )
    
    async def _simulate_user_read_activity(self, session: aiohttp.ClientSession, 
                                         user_id: int, end_time: float,
                                         results: List, errors: List):
        """ì‚¬ìš©ì ì½ê¸° í™œë™ ì‹œë®¬ë ˆì´ì…˜"""
        request_count = 0
        
        while time.time() < end_time:
            try:
                # ë‹¤ì–‘í•œ API ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
                company_id = self.test_company_ids[request_count % len(self.test_company_ids)]
                
                endpoints = [
                    f"{self.base_url}/api/v1/graph/optimized/company/{company_id}",
                    f"{self.base_url}/api/v1/graph/optimized/company/{company_id}/connections",
                    f"{self.base_url}/api/v1/graph/optimized/company/{company_id}/network-risk",
                    f"{self.base_url}/api/v1/graph/stats"
                ]
                
                endpoint = endpoints[request_count % len(endpoints)]
                result = await self._make_http_request(session, endpoint)
                results.append(result)
                
                if not result["success"]:
                    errors.append(f"User {user_id}: {result['error']}")
                
                request_count += 1
                
                # ì‚¬ìš©ì ê°„ ìš”ì²­ ê°„ê²© (100-300ms)
                await asyncio.sleep(0.1 + (user_id % 3) * 0.1)
                
            except Exception as e:
                errors.append(f"User {user_id} exception: {str(e)}")
                await asyncio.sleep(1)  # ì—ëŸ¬ ì‹œ ì ì‹œ ëŒ€ê¸°
    
    async def write_throughput_test(self, duration_seconds: int = 30) -> LoadTestResult:
        """ì“°ê¸° ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸ (ëª©í‘œ: > 100 TPS)"""
        logger.info(f"Running write throughput test for {duration_seconds}s")
        
        results = []
        errors = []
        start_time = time.time()
        
        # ë™ì‹œ ì“°ê¸° ì‘ì—… ì‹¤í–‰
        tasks = []
        for worker_id in range(10):  # 10ê°œ ì›Œì»¤
            task = asyncio.create_task(
                self._write_worker(worker_id, start_time + duration_seconds, results, errors)
            )
            tasks.append(task)
        
        await asyncio.gather(*tasks)
        
        actual_duration = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        successful_writes = [r for r in results if r["success"]]
        failed_writes = [r for r in results if not r["success"]]
        
        if successful_writes:
            response_times = [r["response_time_ms"] for r in successful_writes]
            avg_response_time = statistics.mean(response_times)
            p95_response_time = sorted(response_times)[int(len(response_times) * 0.95)]
            p99_response_time = sorted(response_times)[int(len(response_times) * 0.99)]
            max_response_time = max(response_times)
            min_response_time = min(response_times)
        else:
            avg_response_time = p95_response_time = p99_response_time = 0
            max_response_time = min_response_time = 0
        
        tps = len(successful_writes) / actual_duration
        success_rate = len(successful_writes) / len(results) * 100 if results else 0
        
        return LoadTestResult(
            test_name="Write Throughput Test",
            concurrent_users=10,
            total_requests=len(results),
            duration_seconds=actual_duration,
            requests_per_second=tps,
            successful_requests=len(successful_writes),
            failed_requests=len(failed_writes),
            success_rate=success_rate,
            avg_response_time_ms=avg_response_time,
            p95_response_time_ms=p95_response_time,
            p99_response_time_ms=p99_response_time,
            max_response_time_ms=max_response_time,
            min_response_time_ms=min_response_time,
            errors=errors[:10],
            goal_achieved=tps >= 100 and success_rate >= 95  # ëª©í‘œ: 100 TPS, 95% ì„±ê³µë¥ 
        )
    
    async def _write_worker(self, worker_id: int, end_time: float, 
                          results: List, errors: List):
        """ì“°ê¸° ì›Œì»¤"""
        write_count = 0
        
        while time.time() < end_time:
            try:
                # Neo4jì— ì§ì ‘ ì“°ê¸° (ë” ì •í™•í•œ TPS ì¸¡ì •)
                company_id = f"load-test-write-{worker_id}-{write_count}"
                
                start_time = time.time()
                
                query = """
                CREATE (c:Company {
                    id: $company_id,
                    name: $name,
                    sector: 'LoadTest',
                    risk_score: $risk_score,
                    created_at: timestamp()
                })
                """
                
                driver.execute_write(
                    query,
                    company_id=company_id,
                    name=f"Load Test Company {worker_id}-{write_count}",
                    risk_score=5.0 + (write_count % 5)
                )
                
                response_time = (time.time() - start_time) * 1000
                
                results.append({
                    "success": True,
                    "response_time_ms": response_time,
                    "worker_id": worker_id,
                    "write_count": write_count
                })
                
                write_count += 1
                
                # ì“°ê¸° ê°„ê²© ì¡°ì • (TPS ì œì–´)
                await asyncio.sleep(0.01)  # 100 TPS ëª©í‘œ
                
            except Exception as e:
                response_time = (time.time() - start_time) * 1000 if 'start_time' in locals() else 1000
                
                results.append({
                    "success": False,
                    "response_time_ms": response_time,
                    "worker_id": worker_id,
                    "error": str(e)
                })
                
                errors.append(f"Worker {worker_id}: {str(e)}")
                await asyncio.sleep(0.1)  # ì—ëŸ¬ ì‹œ ì§§ì€ ëŒ€ê¸°
    
    async def mixed_workload_test(self, duration_seconds: int = 60) -> LoadTestResult:
        """í˜¼í•© ì›Œí¬ë¡œë“œ í…ŒìŠ¤íŠ¸ (ì½ê¸° 80%, ì“°ê¸° 20%)"""
        logger.info(f"Running mixed workload test for {duration_seconds}s")
        
        results = []
        errors = []
        start_time = time.time()
        end_time = start_time + duration_seconds
        
        # ì½ê¸°/ì“°ê¸° ì›Œì»¤ ë™ì‹œ ì‹¤í–‰
        async with aiohttp.ClientSession() as session:
            tasks = []
            
            # ì½ê¸° ì›Œì»¤ (80%)
            for i in range(8):
                task = asyncio.create_task(
                    self._simulate_user_read_activity(session, i, end_time, results, errors)
                )
                tasks.append(task)
            
            # ì“°ê¸° ì›Œì»¤ (20%)
            for i in range(2):
                task = asyncio.create_task(
                    self._write_worker(f"mixed-{i}", end_time, results, errors)
                )
                tasks.append(task)
            
            await asyncio.gather(*tasks)
        
        actual_duration = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        successful_requests = [r for r in results if r.get("success", False)]
        failed_requests = [r for r in results if not r.get("success", True)]
        
        if successful_requests:
            response_times = [r["response_time_ms"] for r in successful_requests]
            avg_response_time = statistics.mean(response_times)
            p95_response_time = sorted(response_times)[int(len(response_times) * 0.95)]
            p99_response_time = sorted(response_times)[int(len(response_times) * 0.99)]
            max_response_time = max(response_times)
            min_response_time = min(response_times)
        else:
            avg_response_time = p95_response_time = p99_response_time = 0
            max_response_time = min_response_time = 0
        
        rps = len(results) / actual_duration
        success_rate = len(successful_requests) / len(results) * 100 if results else 0
        
        return LoadTestResult(
            test_name="Mixed Workload Test",
            concurrent_users=10,
            total_requests=len(results),
            duration_seconds=actual_duration,
            requests_per_second=rps,
            successful_requests=len(successful_requests),
            failed_requests=len(failed_requests),
            success_rate=success_rate,
            avg_response_time_ms=avg_response_time,
            p95_response_time_ms=p95_response_time,
            p99_response_time_ms=p99_response_time,
            max_response_time_ms=max_response_time,
            min_response_time_ms=min_response_time,
            errors=errors[:10],
            goal_achieved=rps >= 75 and success_rate >= 90  # í˜¼í•© ì›Œí¬ë¡œë“œ ëª©í‘œ
        )
    
    async def run_all_load_tests(self) -> Dict[str, Any]:
        """ëª¨ë“  ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("Starting comprehensive load testing")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì •
        await self.setup_test_data()
        
        # ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        tests = [
            await self.concurrent_read_test(concurrent_users=100, duration_seconds=30),
            await self.write_throughput_test(duration_seconds=30),
            await self.mixed_workload_test(duration_seconds=60)
        ]
        
        self.results = tests
        
        # ê²°ê³¼ ìš”ì•½
        total_tests = len(tests)
        passed_tests = sum(1 for t in tests if t.goal_achieved)
        
        summary = {
            "load_test_timestamp": datetime.now().isoformat(),
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "overall_success_rate": passed_tests / total_tests * 100,
            "sprint1_load_goals_met": passed_tests >= 2,
            "performance_summary": {
                "concurrent_reads": f"{tests[0].requests_per_second:.1f} RPS",
                "write_throughput": f"{tests[1].requests_per_second:.1f} TPS",
                "mixed_workload": f"{tests[2].requests_per_second:.1f} RPS"
            },
            "detailed_results": [asdict(t) for t in tests]
        }
        
        return summary
    
    def print_results(self):
        """ê²°ê³¼ ì¶œë ¥"""
        if not self.results:
            print("No load test results available")
            return
        
        print("\n" + "="*80)
        print("GRAPH SERVICE LOAD TEST RESULTS")
        print("="*80)
        
        for result in self.results:
            status = "âœ… PASS" if result.goal_achieved else "âŒ FAIL"
            
            print(f"\n{result.test_name}")
            print(f"Status: {status}")
            print(f"Concurrent Users: {result.concurrent_users}")
            print(f"Duration: {result.duration_seconds:.1f}s")
            print(f"Total Requests: {result.total_requests}")
            print(f"RPS/TPS: {result.requests_per_second:.2f}")
            print(f"Success Rate: {result.success_rate:.1f}%")
            print(f"Avg Response Time: {result.avg_response_time_ms:.2f}ms")
            print(f"P95 Response Time: {result.p95_response_time_ms:.2f}ms")
            print(f"P99 Response Time: {result.p99_response_time_ms:.2f}ms")
            if result.errors:
                print(f"Sample Errors: {result.errors[:3]}")
        
        # ì „ì²´ ìš”ì•½
        passed = sum(1 for r in self.results if r.goal_achieved)
        total = len(self.results)
        
        print(f"\n" + "-"*80)
        print(f"LOAD TEST SUMMARY")
        print(f"Tests Passed: {passed}/{total}")
        print(f"Success Rate: {passed/total*100:.1f}%")
        
        if passed >= total * 0.67:  # ìµœì†Œ 2/3 í†µê³¼
            print("ğŸš€ Sprint 1 Load Goals: ACHIEVED")
        else:
            print("âš ï¸  Sprint 1 Load Goals: NEEDS IMPROVEMENT")
        
        print("="*80)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("http://localhost:8003/health") as response:
                if response.status != 200:
                    logger.error("Graph service is not healthy")
                    sys.exit(1)
    except Exception as e:
        logger.error(f"Cannot connect to graph service: {e}")
        logger.error("Please make sure the service is running on port 8003")
        sys.exit(1)
    
    load_test = GraphServiceLoadTest()
    
    try:
        # ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = await load_test.run_all_load_tests()
        
        # ê²°ê³¼ ì¶œë ¥
        load_test.print_results()
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        output_file = f"load_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nDetailed results saved to: {output_file}")
        
        # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ì— ë”°ë¥¸ ì¢…ë£Œ ì½”ë“œ
        if results["sprint1_load_goals_met"]:
            sys.exit(0)
        else:
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"Load test failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())